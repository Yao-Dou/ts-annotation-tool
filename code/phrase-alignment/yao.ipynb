{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'One side of the armed conflicts is composed mainly of the Sudanese military and the Janjaweed, a Sudanese militia group recruited mostly from the Afro-Arab Abbala tribes of the northern Rizeigat region in Sudan.', 'simplified': 'one side of the armed conflicts is composed of the sudanese military and the janjaweed , a sudanese militia group recruited from the afro-arab abbala tribes of the northern rizeigat in sudan .', 'system': 'editnts_w_split.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Converts Yao's CSV to a json\n",
    "csv_path = 'data/input_yao.csv'\n",
    "json_path = 'data/input_yao.json'\n",
    "\n",
    "with open(csv_path, encoding='utf-8') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "\n",
    "    out = []\n",
    "    \n",
    "    i = 0\n",
    "    for row in csv_reader:\n",
    "        if (i==0):\n",
    "            print(row)\n",
    "        i+=1\n",
    "        \n",
    "        out.append(row)\n",
    "        \n",
    "    with open(json_path, 'w', encoding='utf-8') as jsonf:\n",
    "        jsonf.write(json.dumps(out, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment is having trouble with long sentences\n",
    "# Gets longest sentences\n",
    "json_path = 'data/input_yao.json'\n",
    "\n",
    "with open(json_path, encoding='utf-8') as f:\n",
    "    in_data = json.load(f).copy()\n",
    "\n",
    "for i in range(len(in_data)):\n",
    "    in_data[i]['id'] = i\n",
    "\n",
    "sorted_sents = sorted(in_data, key=lambda x: len(x['simplified']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the list of sentences which haven't been aligned\n",
    "in_no_exist = []\n",
    "not_found = []\n",
    "for i in range(len(sorted_sents)):\n",
    "    sent = sorted_sents[i]['id']\n",
    "    found = False\n",
    "    for idx_pair in no_exist_idx:\n",
    "        if sent >= idx_pair[0] and sent <= idx_pair[1]:\n",
    "            in_no_exist.append(True)\n",
    "            found = True\n",
    "            not_found.append(sorted_sents[i])\n",
    "            break\n",
    "    if not found:\n",
    "        in_no_exist.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90-100\n",
      "150-200\n",
      "275-300\n",
      "325-350\n",
      "400-425\n",
      "650-675\n",
      "700-750\n",
      "775-800\n",
      "950-975\n",
      "1025-1050\n",
      "1250-1275\n",
      "1350-1375\n",
      "1425-1525\n",
      "1625-1700\n",
      "1725-1800\n",
      "2050-2100\n",
      "2525-2550\n",
      "3000-3025\n",
      "3050-3075\n",
      "3150-3175\n"
     ]
    }
   ],
   "source": [
    "# Checks to make sure alignments exist\n",
    "import os\n",
    "files = [x for x in os.listdir(os.getcwd() + \"/data\") if x.startswith(\"input_yao_aligned_\")]\n",
    "aligned_idxes = sorted([[int(x.replace(\".json\", \"\")) for x in f.split(\"_\")[3:5]] for f in files])\n",
    "\n",
    "curr_idx = 0\n",
    "no_exist_idx = []\n",
    "for i in range(len(aligned_idxes)-1):\n",
    "    if (aligned_idxes[i][0] != curr_idx):\n",
    "        no_exist_idx.append([curr_idx, aligned_idxes[i][0]])\n",
    "        print(f\"{curr_idx}-{aligned_idxes[i][0]}\")\n",
    "    curr_idx = aligned_idxes[i][1]\n",
    "\n",
    "# Remember! There's no check to see if the same sentence has been processed twice, or if these overlap with each other, this won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "aligned_json_path = 'data/input_yao_aligned.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines alignements\n",
    "combined = []\n",
    "for path in files:\n",
    "    with open(\"data/\" + path, encoding='utf-8') as f:\n",
    "        combined.extend(json.load(f).copy())\n",
    "\n",
    "combined = sorted(combined, key=lambda x: x['id'])\n",
    "\n",
    "with open(aligned_json_path, 'w', encoding='utf-8') as jsonf:\n",
    "    jsonf.write(json.dumps(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "aligned_formatted_json_path = 'data/input_yao_formatted.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert's output json to Yao's requested format\n",
    "with open(aligned_json_path, encoding='utf-8') as f:\n",
    "    aligned = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format: [edit_category, start_index, end_index, edit_id_in_that_category]\n",
    "# 'deletion': 0, 'paraphrase': 1, 'split': 2, 'insertion': 3\n",
    "\n",
    "newly_aligned = []\n",
    "\n",
    "for sent_idx in range(len(aligned)):\n",
    "    newly_aligned_entries = []\n",
    "    \n",
    "    insertion_count = 0\n",
    "    deletion_count = 0\n",
    "    paraphrase_count = 0\n",
    "    \n",
    "    original_spans = []\n",
    "    simplified_spans = []\n",
    "    \n",
    "    for entry in aligned[sent_idx]['spans']:\n",
    "        if (entry[0] == None):\n",
    "            # insertion\n",
    "            simplified_spans.append([3, entry[1][0], entry[1][1], insertion_count])\n",
    "            insertion_count += 1\n",
    "        elif (entry[1] == None):\n",
    "            # deletion\n",
    "            original_spans.append([0, entry[0][0], entry[0][1], deletion_count])\n",
    "            deletion_count += 1\n",
    "        else:\n",
    "            # paraphrase\n",
    "            original_spans.append([1, entry[0][0], entry[0][1], paraphrase_count])\n",
    "            simplified_spans.append([1, entry[1][0], entry[1][1], paraphrase_count])\n",
    "            paraphrase_count += 1\n",
    "            \n",
    "    newly_aligned_entries = aligned[sent_idx].copy()\n",
    "    newly_aligned_entries['original_spans'] = original_spans\n",
    "    newly_aligned_entries['simplified_spans'] = simplified_spans\n",
    "    del newly_aligned_entries['spans']\n",
    "    newly_aligned.append(newly_aligned_entries)\n",
    "\n",
    "newly_aligned = sorted(newly_aligned, key=lambda x: x['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(aligned_formatted_json_path, 'w', encoding='utf-8') as jsonf:\n",
    "    jsonf.write(json.dumps(newly_aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't have alignments for: [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: return missing IDs\n",
    "ids = [x['id'] for x in newly_aligned]\n",
    "noalignment = []\n",
    "for i in range(newly_aligned[-1]['id']):\n",
    "    if i not in ids:\n",
    "        noalignment.append(i)\n",
    "\n",
    "print(f\"Don't have alignments for: {noalignment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
