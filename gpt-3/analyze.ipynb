{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_dist(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n",
    "def avg(lst, prec=2):\n",
    "    if len(lst) == 0:\n",
    "        return 0\n",
    "    return round(sum(lst) / len(lst), prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-system Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "human_systems = {\n",
    "    'systems/asset.test.simp': 'asset',\n",
    "    'new_systems/turk_corpus_random.txt': 'turk-corpus',\n",
    "    'new_systems/simple_wiki.txt': 'simple-wiki',\n",
    "    'new_systems/our_human_written': 'our-data'\n",
    "}\n",
    "\n",
    "path = 'gpt-outputs/cross-dataset-demonstrations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for system in human_systems.keys():\n",
    "    with open(f'{path}/few-shot-batch-2-{human_systems[system]}.json') as f:\n",
    "        data[system] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query import load_batch\n",
    "orig = [str(x[0]) for x in load_batch('batch-2.csv')]\n",
    "gold = [str(x[1]) for x in load_batch('ourdata/batch-2-human.csv')]\n",
    "human_systems['gold/our_human_written'] = 'gold-standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'gpt-outputs/zero-shot-batch-2.json') as f:\n",
    "    data['systems/zero-shot'] = json.load(f)\n",
    "human_systems['systems/zero-shot'] = 'zero-shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "interwoven = []\n",
    "for i in range(min([len(x) for x in data.values()])):\n",
    "    entry = {}\n",
    "    for system in data.keys():\n",
    "        entry[system] = data[system][i]        \n",
    "    entry['gold/our_human_written'] = gold[i]\n",
    "    entry['original'] = orig[i]\n",
    "    interwoven.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from original sentence:\n",
      "{'systems/asset.test.simp': 97.67, 'new_systems/turk_corpus_random.txt': 86.5, 'new_systems/simple_wiki.txt': 96.5, 'new_systems/our_human_written': 97.61, 'gold/our_human_written': 104.89, 'systems/zero-shot': 107.33}\n",
      "distance from human written simplification:\n",
      "{'systems/asset.test.simp': 115.33, 'new_systems/turk_corpus_random.txt': 112.06, 'new_systems/simple_wiki.txt': 117.78, 'new_systems/our_human_written': 114.39, 'gold/our_human_written': 0.0, 'systems/zero-shot': 123.72}\n"
     ]
    }
   ],
   "source": [
    "edit_dists = {k: [] for k, v in human_systems.items()}\n",
    "for sent in interwoven: \n",
    "    for system in human_systems.keys():\n",
    "        edit_dists[system].append(edit_dist(sent['original'], sent[system]))\n",
    "average_edit_dist = {k: avg(v) for k, v in edit_dists.items()}\n",
    "print(\"distance from original sentence:\")\n",
    "print(average_edit_dist)\n",
    "\n",
    "edit_dists = {k: [] for k, v in human_systems.items()}\n",
    "for sent in interwoven: \n",
    "    for system in human_systems.keys():\n",
    "        edit_dists[system].append(edit_dist(sent['gold/our_human_written'], sent[system]))\n",
    "average_edit_dist = {k: avg(v) for k, v in edit_dists.items()}\n",
    "print(\"distance from human written simplification:\")\n",
    "print(average_edit_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systems/asset.test.simp\n",
      "The club announced on social media that customers managed to restrain the attacker. They also said that they were 'shocked and saddened' by the attack and sent their condolences to the victims and their families.\n",
      "\n",
      "new_systems/turk_corpus_random.txt\n",
      "The club said on social media that customers stopped the gunman. It expressed that it was \"devastated by the senseless attack on our community\" and offered condolences to the victims and their families.\n",
      "\n",
      "new_systems/simple_wiki.txt\n",
      "The club announced on social media that customers stopped the shooter. They expressed that they were \"heartbroken by the senseless attack on our community\" and sent their condolences to the victims and their loved ones.\n",
      "\n",
      "new_systems/our_human_written\n",
      "The club reported on social media that customers prevented the gunman. They said they were “devastated” by the attack and offered their condolences to the victims and their families.\n",
      "\n",
      "systems/zero-shot\n",
      "The club announced on social media that customers had managed to overpower the gunman. They declared that they were \"deeply saddened by the senseless attack on our community\", and offered condolences to those affected and their families.\n",
      "\n",
      "gold/our_human_written\n",
      "On social media, the club said that customers stopped the gunman. They also said that they were “devastated by the senseless attack on our community” and that they felt sorry for the victims and their families.\n",
      "\n",
      "original\n",
      "The club said on social media that customers subdued the gunman, that it was \"devastated by the senseless attack on our community\", and that it offered condolences to the victims and their families.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = interwoven[0]\n",
    "for system in sent.keys():\n",
    "    print(system)\n",
    "    print(sent[system], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `text-davinci-002` vs `text-davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt-outputs/few-shot-batch-1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68100ebfd8724d7685da32482d0e7262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Sentence:', max=29), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.series(i)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allows interactive plotting\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt, random\n",
    "\n",
    "# This is my first time using iPy, so this is a bit clunky...\n",
    "def series(i):\n",
    "    for sent in [x[i] for x in data.values()]:\n",
    "        print(sent + \"\\n\")\n",
    "    return()\n",
    "\n",
    "interact(\n",
    "    series, \n",
    "    i = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(data)-1,\n",
    "        step=1,\n",
    "        description='Sentence:',\n",
    "        orientation='horizontal'\n",
    "    )\n",
    ")\n",
    "\n",
    "# data=[data], \n",
    "# good_deletion=(-20,20,0.5), \n",
    "# good_trivial_insertion=(-20,20,0.5), \n",
    "# good_insertion=(-20,20,0.5), \n",
    "# good_paraphrase=(-20,20,0.5), \n",
    "# good_syntax=(-20,20,0.5), \n",
    "# grammar_error=(-20,20,0.5), \n",
    "# content_error=(-20,20,0.5),\n",
    "# size_calculation=['linear', 'log', 'square', 'none'],\n",
    "# average=[True, False],\n",
    "# user=['all'] + sorted(list(set([sent['user'] for sent in data]))),\n",
    "# display_distribution=[True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_different_models(batch_num_range):\n",
    "    out = []\n",
    "    for batch_num in batch_num_range:\n",
    "        path = os.getcwd()\n",
    "        files = [f'{path}\\\\{x}' for x in os.listdir(path) if 'json' in x and 'few' in x]\n",
    "\n",
    "        d2 = [f for f in files if 'davinci-002' in f and f'batch-{batch_num}' in f]\n",
    "        d3 = [f for f in files if 'davinci-002' not in f and f'batch-{batch_num}' in f]\n",
    "\n",
    "        with open(d2[0]) as f:\n",
    "            data_d2 = json.load(f)\n",
    "\n",
    "        with open(d3[0]) as f:\n",
    "            data_d3 = json.load(f)\n",
    "\n",
    "        filename = f'batch-{batch_num}.csv'\n",
    "        # Load data\n",
    "        with open(filename, encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            data = [row for row in reader]\n",
    "        # Will only use the sentences\n",
    "        orig = [str(x[0]) for x in data]\n",
    "        \n",
    "        for i in range(len(orig)):\n",
    "            out.append({\n",
    "                'batch': batch_num,\n",
    "                'original': orig[i],\n",
    "                'text-davinci-002': data_d2[i],\n",
    "                'text-davinci-003': data_d3[i],\n",
    "                'models-edit-dist': edit_dist(data_d2[i], data_d3[i]),\n",
    "                'orig-edit-dist': edit_dist(orig[i], data_d3[i]),\n",
    "                'models-length-change': len(data_d2[i]) - len(data_d3[i]),\n",
    "            })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_different_models([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.92"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg([x['models-length-change'] for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg([x['models-edit-dist'] for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.65"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg([x['orig-edit-dist'] for x in data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
