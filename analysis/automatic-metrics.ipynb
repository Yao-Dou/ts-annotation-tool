{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib data path: C:\\Users\\heine\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\mpl-data\n",
      "DEBUG:CONFIGDIR=C:\\Users\\heine\\.matplotlib\n",
      "DEBUG:interactive is False\n",
      "DEBUG:platform is win32\n",
      "DEBUG:CACHEDIR=C:\\Users\\heine\\.matplotlib\n",
      "DEBUG:Using fontManager instance from C:\\Users\\heine\\.matplotlib\\fontlist-v330.json\n",
      "INFO:Loading files: ['../data/inspection_rating_annotated/batch_1_ayush.json', '../data/inspection_rating_annotated/batch_1_rachel.json', '../data/inspection_rating_annotated/batch_1_vinayak.json', '../data/inspection_rating_annotated/batch_1_vishnesh.json', '../data/inspection_rating_annotated/batch_2_ayush.json', '../data/inspection_rating_annotated/batch_2_rachel.json', '../data/inspection_rating_annotated/batch_2_vinayak.json', '../data/inspection_rating_annotated/batch_2_vishnesh.json', '../data/inspection_rating_annotated/batch_3_ayush.json', '../data/inspection_rating_annotated/batch_3_rachel.json', '../data/inspection_rating_annotated/batch_3_vinayak.json', '../data/inspection_rating_annotated/batch_3_vishnesh.json', '../data/inspection_rating_annotated/batch_4_ayush.json', '../data/inspection_rating_annotated/batch_4_rachel.json', '../data/inspection_rating_annotated/batch_4_vinayak.json', '../data/inspection_rating_annotated/batch_4_vishnesh.json']\n",
      "\n",
      "INFO:Found users: {'rachel', 'vishnesh', 'ayush', 'vinayak'}\n",
      "\n",
      "WARNING:rachel - Batch 1, HIT 1 (ID 420) has 3 deletion edits but 2 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 1, HIT 49 (ID 564) has 2 split edits but 1 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 1, HIT 52 (ID 573) has 1 split edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 1, HIT 56 (ID 585) has 4 insertion edits but 3 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 1, HIT 97 (ID 708) has 7 substitution edits but 6 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:vinayak - Batch 2, HIT 307 (ID 920) has 2 substitution edits but 1 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 2, HIT 311 (ID 931) has 4 substitution edits but 3 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 2, HIT 321 (ID 961) has 9 substitution edits but 8 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 2, HIT 373 (ID 1117) has 1 split edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:vinayak - Batch 3, HIT 488 (ID 1201) has 3 deletion edits but 2 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:vinayak - Batch 3, HIT 488 (ID 1201) has 5 structure edits but 4 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:ayush - Batch 3, HIT 573 (ID 1455) has 3 reorder edits but 2 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 3, HIT 579 (ID 1474) has 1 deletion edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 3, HIT 587 (ID 1498) has 1 structure edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:Annotation doesnt exist for edit\n",
      "WARNING:Annotation doesnt exist for edit\n",
      "WARNING:Annotation doesnt exist for edit\n",
      "WARNING:rachel - Batch 4, HIT 605 (ID 1552) has 5 substitution edits but 4 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 3, HIT 426 (ID 1635) has 1 deletion edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 3, HIT 475 (ID 1782) has 2 structure edits but 1 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 3, HIT 479 (ID 1794) has 2 deletion edits but 1 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 673 (ID 2017) has 1 split edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 675 (ID 2023) has 3 substitution edits but 2 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 679 (ID 2035) has 4 substitution edits but 3 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:Annotation doesnt exist for edit\n",
      "WARNING:rachel - Batch 4, HIT 686 (ID 2056) has 2 deletion edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 686 (ID 2056) has 4 substitution edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 686 (ID 2056) has 1 split edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 686 (ID 2056) has 3 reorder edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 686 (ID 2056) has 1 structure edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:Annotation doesnt exist for edit\n",
      "WARNING:rachel - Batch 4, HIT 692 (ID 2074) has 5 deletion edits but 4 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:rachel - Batch 4, HIT 699 (ID 2095) has 1 insertion edits but 0 annotations. Likely a missing annotation. Skipping edit type...\n",
      "WARNING:No deletion annotation found. Skipping...\n",
      "DEBUG:Couldn't process grammar for deletion: ['bad', '', 'no', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'a lot', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process coreference error for deletion: ['bad', 'minor', '', 'no']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['', '', 'no', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['', '', 'no', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['very', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'somewhat', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process coreference error for deletion: ['bad', 'minor', '', 'no']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes POS', '', 'positive', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes clause', '', 'positive', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['trivial', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process coreference error for deletion: ['bad', 'somewhat', '', 'no']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['trivial', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['trivial', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'somewhat', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['negative', '', 'a lot', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['negative', '', 'a lot', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process coreference error for deletion: ['bad', 'a lot', '', 'no']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['changes tense', '', 'positive', '', 'no']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes clause', '', 'no', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['changes clause', '', 'no', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes grammatical number', '', 'positive', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['trivial', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['negative', '', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['negative', '', 'minor', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes tense', 'minor', 'negative', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['changes tense', 'minor', 'negative', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for deletion: ['good', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes clause', '', 'positive', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['changes POS', '', 'positive', 'minor', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['no', '', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process positive rating for substitution: ['no', '', '', '']. Assuming 'somewhat'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'somewhat', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n",
      "DEBUG:Couldn't process grammar for substitution: ['positive', 'minor', '', '']. Assuming 'no'...\n"
     ]
    }
   ],
   "source": [
    "from utils.all import *\n",
    "log.basicConfig(level=log.INFO)\n",
    "\n",
    "# data = load_data('../annotated', batch_num=[5, 6, 7, 8, 9], preprocess=True)\n",
    "data = load_data('../data/inspection_rating_annotated', preprocess=True, adjudicated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4548019047027907\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "hypothesis = ['It', 'is', 'a', 'cat', 'at', 'room']\n",
    "reference = ['It', 'is', 'a', 'cat', 'inside', 'the', 'room']\n",
    "#there may be several references\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
    "print(BLEUscore)\n",
    "\n",
    "def BLEUsent(hypothesis, references):\n",
    "    ref = [x.split(' ') for x in references]\n",
    "    hyp = hypothesis.split(' ')\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu(ref, hyp)\n",
    "    return BLEUscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should use this library because it's standardized and does tokenization\n",
    "# more accurately\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2682782411698074\n",
      "0.5889995423074248\n",
      "0.5071608864657479\n",
      "(0.7714826593972436, 0.75, 0.0, 0.5071608864657479)\n"
     ]
    }
   ],
   "source": [
    "from utils.sari import *\n",
    "fnamenorm   = \"./turkcorpus/test.8turkers.tok.norm\"\n",
    "fnamesimp   = \"./turkcorpus/test.8turkers.tok.simp\"\n",
    "fnameturk  = \"./turkcorpus/test.8turkers.tok.turk.\"\n",
    "\n",
    "ssent = \"About 95 species are currently accepted .\"\n",
    "csent1 = \"About 95 you now get in .\"\n",
    "csent2 = \"About 95 species are now agreed .\"\n",
    "csent3 = \"About 95 species are currently agreed .\"\n",
    "rsents = [\"About 95 species are currently known .\", \"About 95 species are now accepted .\", \"95 species are now accepted .\"]\n",
    "\n",
    "print(SARIsent(ssent, csent1, rsents))\n",
    "print(SARIsent(ssent, csent2, rsents))\n",
    "print(SARIsent(ssent, csent3, rsents))\n",
    "print(SARIsent(ssent, csent3, rsents, components=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:Creating converter from 7 to 5\n",
      "DEBUG:Creating converter from 5 to 7\n",
      "DEBUG:Creating converter from 7 to 5\n",
      "DEBUG:Creating converter from 5 to 7\n",
      "DEBUG:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:https://huggingface.co:443 \"HEAD /roberta-large/resolve/main/tokenizer_config.json HTTP/1.1\" 404 0\n",
      "DEBUG:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:https://huggingface.co:443 \"HEAD /roberta-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:https://huggingface.co:443 \"HEAD /roberta-large/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:https://huggingface.co:443 \"HEAD /roberta-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22\n"
     ]
    }
   ],
   "source": [
    "import bert_score as bs\n",
    "from bert_score import BERTScorer\n",
    "from utils.util import avg\n",
    "\n",
    "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "\n",
    "def BERTSCOREsent(hypothesis, references):\n",
    "    hypothesis_all = [hypothesis for _ in range(len(references))]\n",
    "    _, _, F1 = scorer.score(hypothesis_all, references)\n",
    "    return avg(F1.tolist())\n",
    "\n",
    "print(BERTSCOREsent(csent1, rsents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install unbabel-comet\n",
    "# import comet # Import order matters! If you import everything first, you will get a WinError 127 because of incompatible libraries\n",
    "# comet_model_path = comet.download_model('wmt21-comet-mqm')\n",
    "# comet_mqm = comet.load_from_checkpoint(comet_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.device_count()\n",
    "#     torch.cuda.current_device()\n",
    "#     torch.cuda.device(0)\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "# else:\n",
    "#     print(\"No CUDA :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [\n",
    "#     {\n",
    "#         \"src\": \"Dem Feuer konnte Einhalt geboten werden\",\n",
    "#         \"mt\": \"The fire could be stopped\",\n",
    "#         \"ref\": \"They were able to control the fire.\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"src\": \"Schulen und Kindergärten wurden eröffnet.\",\n",
    "#         \"mt\": \"Schools and kindergartens were open\",\n",
    "#         \"ref\": \"Schools and kindergartens opened\"\n",
    "#     }\n",
    "# ]\n",
    "# model_output = comet_mqm.predict(data, batch_size=8, gpus=1)\n",
    "# seg_scores, system_score = model_output.scores, model_output.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMET is giving an ambiguous pickle error, likely a problem with imports\n",
    "# You can paste this code into Google Collab and it'll run fine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35050527719306973\n",
      "0.17490733920105417\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "source = \"On the fifth day of flight, November 20, 2022, at 19:09 UTC, the Orion spacecraft entered the Lunar sphere of influence, thus the Moon's gravitational force became stronger than Earth's relative to the spacecraft.\"\n",
    "simplification = \"On November 20, 2022, the Orion spacecraft started to be affected by the Moon's gravity more than Earth's. This happened at 19:09 UTC, after five days of flight.\"\n",
    "references = [\n",
    "    \"On the fifth day of flight, the Orion spaceship entered the Lunar sphere of influence. This means that the Moon's gravitational force could influence the spaceship more than the Earth's.\",\n",
    "    \"On November 20, 2022, at 19:09 UTC, the Orion spacecraft entered the Lunar sphere of influence. This meant that the Moon was pulling the spacecraft with more gravitational force than the Earth.\"\n",
    "]\n",
    "\n",
    "print(SARIsent(source, simplification, references))\n",
    "print(BLEUsent(simplification, references))\n",
    "print(BERTSCOREsent(simplification, references))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x['original'] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sensitivity with scores for 2100 sentences\n"
     ]
    }
   ],
   "source": [
    "# Create a scores list with references and simplifications\n",
    "scores = []\n",
    "for orig in set([x['original'] for x in data]):\n",
    "    sents = [sent for sent in data if sent['original'] == orig]\n",
    "\n",
    "    humans = [sent for sent in sents if 'Human' in sent['system']]\n",
    "    systems = [sent for sent in sents if 'Human' not in sent['system']]\n",
    "\n",
    "    if len(systems) == 0:\n",
    "        continue\n",
    "\n",
    "    for system in systems:\n",
    "        references = list(set([sent['simplified'] for sent in humans]))\n",
    "        prediction = system['simplified']\n",
    "        \n",
    "        # if system['simpeval_scores'] is None:\n",
    "        #     continue\n",
    "        # simpeval_score = avg(system['simpeval_scores'])\n",
    "\n",
    "        score = {\n",
    "            'original': orig,\n",
    "            'simplified': prediction,\n",
    "            'references': references,\n",
    "            'system': system['system'],\n",
    "            # 'simpeval': simpeval_score,\n",
    "        }\n",
    "\n",
    "        scores += [score]\n",
    "    \n",
    "    # Add human written outputs with other human output as reference\n",
    "    for human in humans:\n",
    "        reference = list(set([sent['simplified'] for sent in humans if sent['simplified'] != human['simplified']]))\n",
    "        scores += [{\n",
    "            'original': orig,\n",
    "            'simplified': human['simplified'],\n",
    "            'references': reference,\n",
    "            'system': human['system'],\n",
    "        }]\n",
    "\n",
    "print(f\"Calculating sensitivity with scores for {len(scores)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n",
      "Skipping corrput sentence...\n"
     ]
    }
   ],
   "source": [
    "# Add calculated scores\n",
    "for score in scores:    \n",
    "    original, prediction, references = score['original'], score['simplified'], score['references']\n",
    "    \n",
    "    # Calculate BLEU\n",
    "    try:\n",
    "        score['bleu'] = BLEUsent(prediction, references)\n",
    "    except Exception:\n",
    "        print(\"Skipping corrput sentence...\")\n",
    "        continue\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    score['bertscore'] = BERTSCOREsent(prediction, references)\n",
    "\n",
    "    # Calculate SARI\n",
    "    score['sari_add'], score['sari_keep'], score['sari_del'], score['sari'] = SARIsent(original, prediction, references, components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write scoring setup to json to add COMET scores\n",
    "with open('../lens/1-scores-no-comet-lens.json', 'w') as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add COMET Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add COMET scores\n",
    "with open('../lens/2-scores-comet-only.json', 'r') as f:\n",
    "    comet_results = json.load(f)\n",
    "\n",
    "for score in scores:\n",
    "    # Ensure both the system and sentence is the same\n",
    "    aligned = [sent for sent in comet_results if \n",
    "        sent['original'] == score['original'] and\n",
    "        sent['system'] == score['system']\n",
    "    ]\n",
    "    \n",
    "    if len(aligned) == 0 or 'comet' not in aligned[0].keys():\n",
    "        score['comet'] = 0\n",
    "        continue\n",
    "    \n",
    "    comet_score = aligned[0]['comet']\n",
    "    score['comet'] = comet_score\n",
    "\n",
    "with open('../lens/3-scores-no-lens.json', 'w') as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add LENS Scores\n",
    "\n",
    "I have the scorer set up at `~/nlprx/lens/lens`. Simply upload the scores with \n",
    "```\n",
    "rsync /mnt/c/Users/heine/Documents/research/ts-annotation-tool/lens/3-scores-no-lens.json dheineman3@sky1.cc.gatech.edu:/nethome/dheineman3/nlprx/lens/lens\n",
    "``` \n",
    "then run `cd ~/nlprx/lens/lens` and `python scoring.py` to get a new file `4-scores.json`. You can download this file with\n",
    "```\n",
    "rsync dheineman3@sky1.cc.gatech.edu:/nethome/dheineman3/nlprx/lens/lens/4-scores.json /mnt/c/Users/heine/Documents/research/ts-annotation-tool/lens/4-scores.json\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
