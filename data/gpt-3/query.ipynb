{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import openai\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample ASSET Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He settled in London, devoting himself chiefly to practical teaching.',\n",
       "  'He lived in London. He was a teacher.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads ASSET's 10 simplifications\n",
    "def load_asset(path):\n",
    "    with open(f'{path}/asset.test.orig', encoding='utf-8') as f:\n",
    "        orig = f.read().splitlines()\n",
    "\n",
    "    simplifications = []\n",
    "    for i in range(10):\n",
    "        with open(f'{path}/asset.test.simp.{i}', encoding='utf-8') as f:\n",
    "            simplifications.append(f.read().splitlines())\n",
    "\n",
    "    asset = {}\n",
    "\n",
    "    counter = 0\n",
    "    for sent in range(len(orig)):\n",
    "        asset[counter] = {\n",
    "            'original': orig[sent],\n",
    "            'simplifications': [x[counter] for x in simplifications]\n",
    "        }\n",
    "        counter += 1\n",
    "    \n",
    "    return asset\n",
    "\n",
    "# Randomly sample 5 ASSET sentences + 1 of their simplifications\n",
    "def sample_asset(asset, num_samples=5):\n",
    "    out = []\n",
    "    for sample in random.sample(list(asset.items()), num_samples):\n",
    "        out.append((sample[1]['original'], random.choice(sample[1]['simplifications'])))\n",
    "    return out\n",
    "\n",
    "asset = load_asset('asset/dataset')\n",
    "sample_asset(asset, num_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key & configure OpenAI API\n",
    "with open('.SECRET') as f:\n",
    "    secret = f.read().strip()\n",
    "openai.organization = \"org-wAc6SximlF8c4j1M4IepuYrV\"\n",
    "openai.api_key = secret\n",
    "\n",
    "# Load data\n",
    "with open('text-simplification-new-wikipedia.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Will only use the sentences\n",
    "data = [str(x[0]) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callGPT(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\", \n",
    "        prompt=prompt, \n",
    "        temperature=1,\n",
    "        top_p=0.96,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        max_tokens=256)\n",
    "    responses = [x['text'] for x in response['choices']]\n",
    "    if len(responses) > 1:\n",
    "        print(f\"More than one response! {responses}\")\n",
    "    responses = responses[0]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_prompt = \"\"\"\n",
    "# Sentence: The library needs to be configured with your account's secret key.\n",
    "# Simplify the above sentence.\n",
    "# \"\"\"\n",
    "\n",
    "# callGPT(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English. You can do so by replacing complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compression), and/or splitting a long complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\n",
      "\n",
      "The architecture of Winchester College is a diverse set of architectural styles, reflecting the multiple periods of building from the college's foundation in 1382, through additions in the medieval and Early Modern periods, to a major expansion of accommodation in the Victorian era and then further extensions at the turn of the 20th century and more recently.\n",
      "\n",
      "\n",
      "The architecture of Winchester College is a diverse set of architectural styles. It reflects the multiple periods of building from the college's foundation in 1382, through additions in the medieval and Early Modern periods, to a major expansion of accommodation in the Victorian era. There were also further extensions at the turn of the 20th century and more recently.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English. You can do so by replacing complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compression), and/or splitting a long complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\\n\\n%s\"\n",
    "print(prompt % data[0])\n",
    "print(callGPT(prompt % data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for sent in data:\n",
    "    out.append(callGPT(prompt % sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cleaned = [sent.replace('\\n', '') for sent in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt3-output.json', 'w') as f:\n",
    "    json.dump(out_cleaned, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query OpenAI with Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = \"\"\"\n",
    "Examples: %s\n",
    "\"\"\"\n",
    "\n",
    "example_template = \"\"\"\n",
    "Input: %s\n",
    "Output: %s\n",
    "\"\"\"\n",
    "\n",
    "input_template = \"\"\"\n",
    "Input: %s\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples: \n",
      "Input: The spacecraft consists of two main elements: the NASA Cassini orbiter, named after the Italian-French astronomer Giovanni Domenico Cassini, and the ESA Huygens probe, named after the Dutch astronomer, mathematician and physicist Christiaan Huygens.\n",
      "Output: The spacecraft's two main elements are the NASA Cassini orbiter, named after the Italian-French astronomer Giovanni Domenico Cassini, and the ESA Huygens probe, named after the Dutch astronomer, mathematician and physicist Christiaan Huygens.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_template % (example_template % sample_asset(asset, num_samples=1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English. You can do so by replacing complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compression), and/or splitting a long complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\n",
      "\n",
      "Examples: \n",
      "Input: Tajikistan, Turkmenistan and Uzbekistan border Afghanistan to the north, Iran to the west, Pakistan to the south and the People's Republic of China to the east.\n",
      "Output: Tajikistan, Turkmenistan and Uzbekistan border Afghanistan to the north. They also border Iran to the west, Pakistan to the south and the People's Republic of China to the east.\n",
      "\n",
      "Input: The two former presidents were later separately charged with mutiny and treason for their roles in the 1979 coup and the 1980 Gwangju massacre.\n",
      "Output: The two former presidents were later charged with mutiny and treason for their roles in the 1979 coup and the 1980 Gwangju massacre.\n",
      "\n",
      "Input: As a result, although many mosques will not enforce violations, both men and women when attending a mosque must adhere to these guidelines.\n",
      "Output: Many mosques will not enforce violations.  But, both men and women must follow the rules when attending a mosque.\n",
      "\n",
      "Input: That is because real estate, businesses and other assets in the underground economies of the Third World can not be used as collateral to raise capital to finance industrial and commercial expansion.\n",
      "Output: Real estate, businesses and other assets in Third World black market economies can't be used as collateral to raise money to finance industrial and commercial growth.\n",
      "\n",
      "Input: This was absorbed into battalions being formed for XI International Brigade.\n",
      "Output: This was put into battalions formed by Xi international brigade.\n",
      "\n",
      "Please rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English. You can do so by replacing complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compression), and/or splitting a long complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\n",
      "\n",
      "Input: The architecture of Winchester College is a diverse set of architectural styles, reflecting the multiple periods of building from the college's foundation in 1382, through additions in the medieval and Early Modern periods, to a major expansion of accommodation in the Victorian era and then further extensions at the turn of the 20th century and more recently.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "def create_few_shot_input(sent, num_samples=5):\n",
    "    example_text = \"\"\n",
    "    for example in sample_asset(asset, num_samples=num_samples):\n",
    "        example_text += (example_template % example)\n",
    "    return (prompt[:-3] + (few_shot_template % example_text) + prompt[:-3] + (input_template % sent)[:-1])\n",
    "gpt_input = create_few_shot_input(data[0])\n",
    "print(gpt_input)\n",
    "print(callGPT(gpt_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danger! Queries OpenAI ~$0.02 per sentence\n",
    "out = []\n",
    "for sent in data:\n",
    "    gpt_input = create_few_shot_input(sent)\n",
    "    out.append(callGPT(gpt_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cleaned = []\n",
    "for sent in out:\n",
    "    cleaned = sent\n",
    "    if cleaned.startswith(' '):\n",
    "        cleaned = cleaned[1:]\n",
    "    if cleaned.startswith('\\n\\n'):\n",
    "        cleaned = cleaned[2:]\n",
    "    out_cleaned.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt3-few-shot-output.json', 'w') as f:\n",
    "    json.dump(out_cleaned, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "\"naive\": \"\"\"\n",
    "Sentence: %s\n",
    "Simplify the above sentence.\n",
    "\"\"\",\n",
    "\"a_lot\": \"\"\"\n",
    "Sentence: %s\n",
    "Simplify the above sentence a lot.\n",
    "\"\"\",\n",
    "\"content_a_lot\": \"\"\"\n",
    "Sentence: %s\n",
    "Simplify the content in the above sentence a lot.\n",
    "\"\"\",\n",
    "\"as_possible\": \"\"\"\n",
    "Sentence: %s\n",
    "Simplify the above sentence as much as possible.\n",
    "\"\"\",\n",
    "\"asset_instructions\": \"\"\"\n",
    "You are given a sentence that need to be rewritten so that they use simpler English. This means that you should reduce the number of difficult words or idioms, simplify complex phrasing, delete information that may not be relevant, and make the sentence more straight-forward. This could be accomplished by applying different transformations to the original sentences. In this task, we ask you to use paraphrasing, compression and/or sentence splitting.\n",
    "\n",
    "Sentence: %s\n",
    "Simplified sentence: \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-f2fa5856f282>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example using the first prompt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The proletarians have nothing to lose but their chains.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# Example using the first prompt\n",
    "sentence = \"The proletarians have nothing to lose but their chains.\"\n",
    "print(prompts[2][1:].replace('%s', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = data[10]\n",
    "# prompt_id = 3\n",
    "# prompt = prompts[prompt_id][1:].replace('%s', sent)\n",
    "\n",
    "# Danger! This costs ~$0.3 for 20 sentences\n",
    "out = []\n",
    "for prompt in prompts:\n",
    "    prompt_out = []\n",
    "    for sent in data:\n",
    "        prompt_out.append(callGPT(prompt[1:].replace('%s', sent)))\n",
    "    out.append(prompt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_new = {}\n",
    "for i in range(len(out)):\n",
    "    prompt_out_new = []\n",
    "    for sent in out[i]:\n",
    "        if len(sent) > 0 and sent[0] == '\\n':\n",
    "            sent = sent[1:]\n",
    "        prompt_out_new.append(sent)\n",
    "    out_new[list(prompts.keys())[i]] = prompt_out_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt3-output.json', 'w') as f:\n",
    "    json.dump(out_new, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Sentences for Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with this is that it may randomly assign the same sentences\n",
    "# to an annotator. This isn't easy to fix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create split of data for annotators\n",
    "annotators = [\n",
    "    'anton', 'ayush', 'kelly', 'rachel', 'vinayak', 'vishnesh'\n",
    "]\n",
    "\n",
    "out = {}\n",
    "for ann in annotators:\n",
    "    out[ann] = []\n",
    "\n",
    "seen = {}\n",
    "tmp = copy.deepcopy(data)\n",
    "\n",
    "SENT_PER_ANN = int(len(data)*2 / len(annotators))\n",
    "if (len(data)*2) % len(annotators):\n",
    "    print(\"Sentences are non-divisible I think...\")\n",
    "\n",
    "ann_pointer = 0\n",
    "while len(tmp) != 0:\n",
    "    sent = random.choice(tmp)\n",
    "    if sent in out[annotators[ann_pointer]]:\n",
    "        print('seen before')\n",
    "\n",
    "    if sent not in seen:\n",
    "        seen[sent] = 0\n",
    "    seen[sent] += 1\n",
    "    out[annotators[ann_pointer]].append(sent)\n",
    "    ann_pointer += 1\n",
    "    if ann_pointer == len(annotators):\n",
    "        ann_pointer = 0\n",
    "    if seen[sent] == 2:\n",
    "        tmp.remove(sent)\n",
    "\n",
    "# Sanity check: annotator with duplicate sentences, should be all\n",
    "# empty\n",
    "import collections\n",
    "sents = [x for x in out.values()]\n",
    "for a in sents:\n",
    "    print([count for item, count in collections.Counter(a).items() if count > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anton 10\n",
      "ayush 10\n",
      "kelly 10\n",
      "rachel 10\n",
      "vinayak 10\n",
      "vishnesh 10\n"
     ]
    }
   ],
   "source": [
    "# Final sentence split per annotator\n",
    "for key in out.keys():\n",
    "    print(key, len(out[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = 'vishnesh'\n",
    "\n",
    "clip = \"\"\n",
    "for sent in out[annotator]:\n",
    "    clip += f'{sent}\\n\\n\\n\\n'\n",
    "\n",
    "import pyperclip\n",
    "pyperclip.copy(clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
