{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import csv\n",
    "\n",
    "# Get API key & configure OpenAI API\n",
    "with open('.SECRET') as f:\n",
    "    secret = f.read().strip()\n",
    "openai.organization = \"org-wAc6SximlF8c4j1M4IepuYrV\"\n",
    "openai.api_key = secret\n",
    "\n",
    "# Load data\n",
    "with open('text-simplification-new-wikipedia.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Will only use the sentences\n",
    "data = [str(x[0]) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prompt = \"\"\"\n",
    "Sentence: The library needs to be configured with your account's secret key.\n",
    "Simplify the above sentence.\n",
    "\"\"\"\n",
    "\n",
    "def callGPT(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\", \n",
    "        prompt=prompt, \n",
    "        max_tokens=256)\n",
    "    responses = [x['text'] for x in response['choices']]\n",
    "    if len(responses) > 1:\n",
    "        print(f\"More than one response! {responses}\")\n",
    "    responses = responses[0]\n",
    "    return responses\n",
    "\n",
    "callGPT(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "\"naive\": \"\"\"\n",
    "Sentence: %s\n",
    "Simply the above sentence.\n",
    "\"\"\",\n",
    "\"a_lot\": \"\"\"\n",
    "Sentence: %s\n",
    "Simply the above sentence a lot.\n",
    "\"\"\",\n",
    "\"content_a_lot\": \"\"\"\n",
    "Sentence: %s\n",
    "Simply the content in the above sentence a lot.\n",
    "\"\"\",\n",
    "\"as_possible\": \"\"\"\n",
    "Sentence: %s\n",
    "Simply the above sentence as much as possible.\n",
    "\"\"\",\n",
    "\"asset_instructions\": \"\"\"\n",
    "You are given a sentence that need to be rewritten so that they use simpler English. This means that you should reduce the number of difficult words or idioms, simplify complex phrasing, delete information that may not be relevant, and make the sentence more straight-forward. This could be accomplished by applying different transformations to the original sentences. In this task, we ask you to use paraphrasing, compression and/or sentence splitting.\n",
    "\n",
    "Sentence: %s\n",
    "Simplified sentence: \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The proletarians have nothing to lose but their chains.\n",
      "Simply the content in the above sentence a lot.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example using the first prompt\n",
    "sentence = \"The proletarians have nothing to lose but their chains.\"\n",
    "print(prompts[2][1:].replace('%s', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = data[10]\n",
    "# prompt_id = 3\n",
    "# prompt = prompts[prompt_id][1:].replace('%s', sent)\n",
    "\n",
    "# Danger! This costs ~$0.3 for 20 sentences\n",
    "out = []\n",
    "for prompt in prompts:\n",
    "    prompt_out = []\n",
    "    for sent in data:\n",
    "        prompt_out.append(callGPT(prompt[1:].replace('%s', sent)))\n",
    "    out.append(prompt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_new = {}\n",
    "for i in range(len(out)):\n",
    "    prompt_out_new = []\n",
    "    for sent in out[i]:\n",
    "        if len(sent) > 0 and sent[0] == '\\n':\n",
    "            sent = sent[1:]\n",
    "        prompt_out_new.append(sent)\n",
    "    out_new[list(prompts.keys())[i]] = prompt_out_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt3-output.json', 'w') as f:\n",
    "    json.dump(out_new, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Sentences for Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with this is that it may randomly assign the same sentences\n",
    "# to an annotator. This isn't easy to fix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "# Create split of data for annotators\n",
    "annotators = [\n",
    "    'anton', 'ayush', 'kelly', 'rachel', 'vinayak', 'vishnesh'\n",
    "]\n",
    "\n",
    "out = {}\n",
    "for ann in annotators:\n",
    "    out[ann] = []\n",
    "\n",
    "seen = {}\n",
    "tmp = copy.deepcopy(data)\n",
    "\n",
    "SENT_PER_ANN = int(len(data)*2 / len(annotators))\n",
    "if (len(data)*2) % len(annotators):\n",
    "    print(\"Sentences are non-divisible I think...\")\n",
    "\n",
    "ann_pointer = 0\n",
    "while len(tmp) != 0:\n",
    "    sent = random.choice(tmp)\n",
    "    if sent in out[annotators[ann_pointer]]:\n",
    "        print('seen before')\n",
    "\n",
    "    if sent not in seen:\n",
    "        seen[sent] = 0\n",
    "    seen[sent] += 1\n",
    "    out[annotators[ann_pointer]].append(sent)\n",
    "    ann_pointer += 1\n",
    "    if ann_pointer == len(annotators):\n",
    "        ann_pointer = 0\n",
    "    if seen[sent] == 2:\n",
    "        tmp.remove(sent)\n",
    "\n",
    "# Sanity check: annotator with duplicate sentences, should be all\n",
    "# empty\n",
    "import collections\n",
    "sents = [x for x in out.values()]\n",
    "for a in sents:\n",
    "    print([count for item, count in collections.Counter(a).items() if count > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anton 10\n",
      "ayush 10\n",
      "kelly 10\n",
      "rachel 10\n",
      "vinayak 10\n",
      "vishnesh 10\n"
     ]
    }
   ],
   "source": [
    "# Final sentence split per annotator\n",
    "for key in out.keys():\n",
    "    print(key, len(out[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = 'vishnesh'\n",
    "\n",
    "clip = \"\"\n",
    "for sent in out[annotator]:\n",
    "    clip += f'{sent}\\n\\n\\n\\n'\n",
    "\n",
    "import pyperclip\n",
    "pyperclip.copy(clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
