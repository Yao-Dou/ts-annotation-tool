{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib data path: C:\\Users\\heine\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\mpl-data\n",
      "DEBUG:CONFIGDIR=C:\\Users\\heine\\.matplotlib\n",
      "DEBUG:interactive is False\n",
      "DEBUG:platform is win32\n",
      "DEBUG:CACHEDIR=C:\\Users\\heine\\.matplotlib\n",
      "DEBUG:Using fontManager instance from C:\\Users\\heine\\.matplotlib\\fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../analysis')\n",
    "from utils.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading files: ['annotated/batch_5_anton.json', 'annotated/batch_5_ayush.json', 'annotated/batch_5_kelly.json', 'annotated/batch_5_rachel.json', 'annotated/batch_5_vinayak.json', 'annotated/batch_5_vishnesh.json', 'annotated/batch_6_anton.json', 'annotated/batch_6_ayush.json', 'annotated/batch_6_kelly.json', 'annotated/batch_6_rachel.json', 'annotated/batch_6_vinayak.json', 'annotated/batch_6_vishnesh.json', 'annotated/batch_7_anton.json', 'annotated/batch_7_ayush.json', 'annotated/batch_7_kelly.json', 'annotated/batch_7_rachel.json', 'annotated/batch_7_vinayak.json', 'annotated/batch_7_vishnesh.json', 'annotated/batch_8_anton.json', 'annotated/batch_8_ayush.json', 'annotated/batch_8_kelly.json', 'annotated/batch_8_rachel.json', 'annotated/batch_8_vinayak.json', 'annotated/batch_8_vishnesh.json', 'annotated/batch_9_anton.json', 'annotated/batch_9_ayush.json', 'annotated/batch_9_kelly.json', 'annotated/batch_9_rachel.json', 'annotated/batch_9_vinayak.json', 'annotated/batch_9_vishnesh.json', 'annotated/batch_10_anton.json', 'annotated/batch_10_ayush.json', 'annotated/batch_10_kelly.json', 'annotated/batch_10_rachel.json', 'annotated/batch_10_vinayak.json', 'annotated/batch_10_vishnesh.json', 'annotated/batch_11_anton.json', 'annotated/batch_11_ayush.json', 'annotated/batch_11_kelly.json', 'annotated/batch_11_rachel.json', 'annotated/batch_11_vinayak.json', 'annotated/batch_11_vishnesh.json']\n",
      "\n",
      "INFO:Found users: {'kelly', 'anton', 'vinayak', 'vishnesh', 'ayush', 'rachel'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export SimpEval_22 and Simpeval_Ext\n",
    "data = load_data('annotated', batch_num=[5, 6, 7, 8, 9, 10, 11], preprocess=False)\n",
    "\n",
    "for sent in data:\n",
    "    sent['system'] = sent['system'] \\\n",
    "        .replace('new-wiki-2', 'simpeval-22') \\\n",
    "        .replace('new-wiki-1', 'simpeval-22') \\\n",
    "        .replace(' Writing', '-written') \\\n",
    "        .replace('Human ', 'Human-') \\\n",
    "        .replace('new-wiki-3', 'simpeval-ext')\n",
    "\n",
    "simpeval_22, simpeval_ext = [], []\n",
    "for sent in data:\n",
    "    if 'simpeval-22' in sent['system']:\n",
    "        simpeval_22 += [sent]\n",
    "    elif 'simpeval-ext' in sent['system']:\n",
    "        simpeval_ext += [sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180: simpeval-22/Human-2-written\n",
      "180: simpeval-22/GPT-3-few-shot\n",
      "180: simpeval-22/GPT-3-zero-shot\n",
      "180: simpeval-22/Human-1-written\n",
      "180: simpeval-22/Muss\n",
      "180: simpeval-22/T5-3B\n",
      "180: simpeval-22/T5-11B\n",
      "\n",
      "120: simpeval-ext/GPT-3-zero-shot\n",
      "120: simpeval-ext/GPT-3-few-shot\n",
      "120: simpeval-ext/T5-11B\n",
      "120: simpeval-ext/Muss\n",
      "120: simpeval-ext/T5-3B\n",
      "120: simpeval-ext/Human-2-written\n",
      "120: simpeval-ext/Human-1-written\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Count the # annotations per system\n",
    "def number_annotations_per_system(data):\n",
    "    systems = set([s['system'] for s in data])\n",
    "    for system in systems:\n",
    "        print(f\"{len([s for s in data if s['system'] == system])}: {system}\")\n",
    "number_annotations_per_system(simpeval_22)\n",
    "print('')\n",
    "number_annotations_per_system(simpeval_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"salsa/simpeval_22.json\", \"w\") as f:\n",
    "   json.dump(simpeval_22, f, indent=4)\n",
    "\n",
    "with open(f\"salsa/simpeval_ext.json\", \"w\") as f:\n",
    "   json.dump(simpeval_ext, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading files: ['annotated/batch_1_anton.json', 'annotated/batch_1_ayush.json', 'annotated/batch_1_kelly.json', 'annotated/batch_2_vinayak.json', 'annotated/batch_2_vishnesh.json', 'annotated/batch_3_anton.json', 'annotated/batch_3_ayush.json', 'annotated/batch_3_kelly.json', 'annotated/batch_4_rachel.json', 'annotated/batch_4_vinayak.json', 'annotated/batch_4_vishnesh.json']\n",
      "\n",
      "INFO:Found users: {'kelly', 'anton', 'vishnesh', 'vinayak', 'ayush', 'rachel'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74: turkcorpus/T5.txt\n",
      "74: turkcorpus/asset.test.simp\n",
      "74: turkcorpus/asset.test.simp.second\n",
      "74: turkcorpus/turk_corpus_random.txt\n",
      "74: turkcorpus/con_simplification.txt\n"
     ]
    }
   ],
   "source": [
    "# Export the preliminary annotations\n",
    "preliminary = load_data('annotated', batch_num=[1, 2, 3, 4], preprocess=False)\n",
    "\n",
    "for sent in preliminary:\n",
    "    sent['system'] = sent['system'] \\\n",
    "        .replace('new_systems', 'turkcorpus') \\\n",
    "        .replace('new_systems', 'turkcorpus') \\\n",
    "        .replace('systems', 'turkcorpus')\n",
    "\n",
    "number_annotations_per_system(preliminary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"salsa/turkcorpus_preliminary.json\", \"w\") as f:\n",
    "   json.dump(preliminary, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Ajudication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simpeval_22 + simpeval_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes 'annotation' or 'annotations' fields\n",
    "def delete_annotations(data):\n",
    "    for s in data:\n",
    "        if 'annotation' in s.keys():\n",
    "            del s['annotation']\n",
    "        if 'annotations' in s.keys():\n",
    "            del s['annotations']\n",
    "\n",
    "# Given a user, for each sentence in interwoven,\n",
    "# have the swap the sentence if their annotation in in\n",
    "# the first poistion\n",
    "def interweave(data, user=None):\n",
    "    interwoven = {}\n",
    "    for sentence_id in set([s['sentence_id'] for s in data]):\n",
    "        sents = [s for s in data if s['sentence_id'] == sentence_id]\n",
    "\n",
    "        # Order user's annotations to be first\n",
    "        if user is not None:\n",
    "            if user not in [s['user'] for s in sents]:\n",
    "                continue\n",
    "            sents = [s for s in sents if s['user'] == user] + [s for s in sents if s['user'] != user]\n",
    "\n",
    "        sents = delete_annotations(sents)\n",
    "\n",
    "        if len(sents) == 1:\n",
    "            sents += [[], []]\n",
    "        elif len(sents) == 2:\n",
    "            sents += [[]]\n",
    "        \n",
    "        for i, s in enumerate(sents):\n",
    "            if i not in interwoven:\n",
    "                interwoven[i] = []\n",
    "            interwoven[i] += [s]\n",
    "    return interwoven\n",
    "\n",
    "# Prepares original ajudication\n",
    "def prepare_adjudiction(data, user=None, ids=None, batch_size=100):\n",
    "    # If the ids are given, simply extract those ids from the data\n",
    "    if ids is not None:\n",
    "        interwoven = {}\n",
    "        for i, id_ in enumerate(ids):\n",
    "            sents = [s for s in data if s['sentence_id'] == id_]\n",
    "            for j, s in enumerate(sents):\n",
    "                if j not in interwoven:\n",
    "                    interwoven[j] = []\n",
    "                interwoven[j] += [s]\n",
    "    else:\n",
    "        interwoven = interweave(data, user=user)\n",
    "\n",
    "    path = f\"inspection\"\n",
    "    if user is not None:\n",
    "        path += f\"/{user}\" \n",
    "\n",
    "    for i in interwoven.keys():\n",
    "        if batch_size is not None and user is not None:\n",
    "            for j in range(math.ceil(len(interwoven[i]) / batch_size)):\n",
    "                end_idx = (j+1)*batch_size\n",
    "                if end_idx >= len(interwoven[i]):\n",
    "                    end_idx = len(interwoven[i])\n",
    "\n",
    "                path = f\"inspection/{user}/batch_{j+1}\"\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                with open(f'{path}/set_{i}.json', \"w\") as f:\n",
    "                    json.dump(interwoven[i][j*batch_size:end_idx], f, indent=4)\n",
    "        else:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            with open(f'{path}/set_{i}.json', \"w\") as f:\n",
    "                json.dump(interwoven[i], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinayak: 170\n",
      "ayush: 187\n",
      "rachel: 172\n",
      "vishnesh: 171\n"
     ]
    }
   ],
   "source": [
    "# If you are reading this code: lord have mercy on your soul\n",
    "# 2 design ideas: \n",
    "    # (1) no annotator fixes spans on an annotations they have seen\n",
    "    # (2) we remove anton and kelly as annotators\n",
    "\n",
    "annotated_sent_id_by_user = {}\n",
    "for sentence_id in set([s['sentence_id'] for s in data]):\n",
    "    sents = [s for s in data if s['sentence_id'] == sentence_id]\n",
    "\n",
    "    for s in sents:\n",
    "        if s['user'] not in annotated_sent_id_by_user:\n",
    "            annotated_sent_id_by_user[s['user']] = []\n",
    "        annotated_sent_id_by_user[s['user']] += [s['sentence_id']]\n",
    "\n",
    "sent_id_by_user = {}\n",
    "for sentence_id in set([s['sentence_id'] for s in data]):\n",
    "    sent_id_by_user[sentence_id] = []\n",
    "    for user in annotated_sent_id_by_user.keys():\n",
    "        if sentence_id in annotated_sent_id_by_user[user]:\n",
    "            sent_id_by_user[sentence_id] += [user]\n",
    "\n",
    "not_annotated_sent_id_by_user = {}\n",
    "for user in annotated_sent_id_by_user.keys():\n",
    "    new_list = []\n",
    "    for sentence_id in set([s['sentence_id'] for s in data]):\n",
    "        if sentence_id not in annotated_sent_id_by_user[user]:\n",
    "            new_list += [sentence_id]\n",
    "    not_annotated_sent_id_by_user[user] = new_list\n",
    "\n",
    "del not_annotated_sent_id_by_user['anton']\n",
    "del not_annotated_sent_id_by_user['kelly']\n",
    "\n",
    "import random\n",
    "\n",
    "picked_users = {}\n",
    "for user in not_annotated_sent_id_by_user.keys():\n",
    "    picked_users[user] = []\n",
    "for sentence_id in set([s['sentence_id'] for s in data]):\n",
    "    candidate_users = [u for u in not_annotated_sent_id_by_user.keys() if sentence_id in not_annotated_sent_id_by_user[u]]\n",
    "    candidate_users = [u for u in candidate_users if u in not_annotated_sent_id_by_user.keys()]\n",
    "    if len(candidate_users) == 0:\n",
    "        raise Exception(f\"No candidate users for sentence {sentence_id}\")\n",
    "    # user = random.choice(candidate_users)\n",
    "    user = min(candidate_users, key=lambda u: len(picked_users[u]))\n",
    "    picked_users[user] += [sentence_id]\n",
    "    \n",
    "for user in picked_users.keys():\n",
    "    print(f\"{user}: {len(picked_users[user])}\")\n",
    "\n",
    "sentence_ids_by_user = picked_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All annotators annotated ~350 sentences\n",
    "# Assign one of those sentences to each annotator - around 117 sentences per annotator. Split into 2 batches\n",
    "interwoven = {}\n",
    "for user in sentence_ids_by_user.keys():\n",
    "    interwoven[user] = prepare_adjudiction(data, user=user, ids=sentence_ids_by_user[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old assignment: Annotators see their own annotations\n",
    "# data = simpeval_22 + simpeval_ext\n",
    "# interwoven = {}\n",
    "# for user in set([s['user'] for s in data]):\n",
    "#     interwoven[user] = interweave(data, user=user)\n",
    "\n",
    "# Old assignment: Separate each of the three annotations of each sentence\n",
    "# data = simpeval_22 + simpeval_ext\n",
    "# prepare_adjudiction(data)\n",
    "# for user in set([s['user'] for s in data]):\n",
    "#     prepare_adjudiction(data, user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
