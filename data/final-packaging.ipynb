{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Injestion\n",
    "Create `simpeval_22_ajudicated.json` and `simpeval_ext_ajudicated.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180: simpeval-22/GPT-3-few-shot\n",
      "180: simpeval-22/Human-1-written\n",
      "180: simpeval-22/Muss\n",
      "180: simpeval-22/GPT-3-zero-shot\n",
      "180: simpeval-22/T5-11B\n",
      "180: simpeval-22/T5-3B\n",
      "180: simpeval-22/Human-2-written\n",
      "\n",
      "120: simpeval-ext/Human-1-written\n",
      "120: simpeval-ext/GPT-3-zero-shot\n",
      "120: simpeval-ext/Human-2-written\n",
      "120: simpeval-ext/GPT-3-few-shot\n",
      "120: simpeval-ext/T5-3B\n",
      "120: simpeval-ext/Muss\n",
      "120: simpeval-ext/T5-11B\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../analysis')\n",
    "# sys.path.append('C:\\Python39\\Lib\\site-packages\\matplotlib')\n",
    "# import matplotlib.artist\n",
    "from utils.all import *\n",
    "from data_util import *\n",
    "log.basicConfig(level=log.INFO)\n",
    "data = load_data('../data/inspection_rating_annotated', preprocess=False, adjudicated=True)\n",
    "\n",
    "simpeval_22, simpeval_ext = [], []\n",
    "for sent in data:\n",
    "    if 'simpeval-22' in sent['system']:\n",
    "        simpeval_22 += [sent]\n",
    "    elif 'simpeval-ext' in sent['system']:\n",
    "        simpeval_ext += [sent]\n",
    "\n",
    "# Sanity check: Count the # annotations per system\n",
    "def number_annotations_per_system(data):\n",
    "    systems = set([s['system'] for s in data])\n",
    "    for system in systems:\n",
    "        print(f\"{len([s for s in data if s['system'] == system])}: {system}\")\n",
    "number_annotations_per_system(simpeval_22)\n",
    "print('')\n",
    "number_annotations_per_system(simpeval_ext)\n",
    "\n",
    "with open(f\"salsa/simpeval_22_ajudicated.json\", \"w\") as f:\n",
    "   json.dump(simpeval_22, f, indent=4)\n",
    "\n",
    "with open(f\"salsa/simpeval_ext_ajudicated.json\", \"w\") as f:\n",
    "   json.dump(simpeval_ext, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LENS-SALSA Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('../data/inspection_rating_annotated', preprocess=True, adjudicated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LENS scores\n",
    "with open('../lens/4-scores.json', 'r') as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "for sent in data:\n",
    "    for score in scores:\n",
    "        if sent['original'] == score['original'] and sent['simplified'] == score['simplified']:\n",
    "            sent['lens_score'] = score['lens']\n",
    "            sent['bleu'] = score['bleu']\n",
    "            sent['bertscore'] = score['bertscore']\n",
    "            sent['sari'] = score['sari']\n",
    "            sent['comet'] = score['comet']\n",
    "\n",
    "# Exclude corrupted sentences with no scores\n",
    "data = [s for s in data if 'bleu' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_data(data):\n",
    "    out_file = []\n",
    "    for sent in data:\n",
    "        entry = {\n",
    "            # 'sentence_id': sent['sentence_id'],\n",
    "            'lp': 'en-en',\n",
    "            'src': sent['original'],\n",
    "            'mt': sent['simplified'],\n",
    "            'system': sent['system'],\n",
    "            'salsa_score': sent['score'],\n",
    "            \n",
    "            'bleu': sent['bleu'] if 'bleu' in sent else None,\n",
    "            'bertscore': sent['bertscore'] if 'bertscore' in sent else None,\n",
    "            'sari': sent['sari'] if 'sari' in sent else None,\n",
    "            'comet': sent['comet'] if 'comet' in sent else None,\n",
    "            'lens_score': sent['lens_score'] if 'lens_score' in sent else None,\n",
    "\n",
    "            'simpeval_score_1': None,\n",
    "            'simpeval_score_2': None,\n",
    "            'simpeval_score_3': None,\n",
    "\n",
    "            # Subscores\n",
    "            'salsa_lexical_quality_score': sent['subscores']['quality_lexical'],\n",
    "            'salsa_syntax_quality_score': sent['subscores']['quality_syntax'],\n",
    "            'salsa_conceptual_quality_score': sent['subscores']['quality_content'],\n",
    "\n",
    "            'salsa_lexical_error_score': sent['subscores']['error_lexical'],\n",
    "            'salsa_syntax_error_score': sent['subscores']['error_syntax'],\n",
    "            'salsa_conceptual_error_score': sent['subscores']['error_content'],\n",
    "\n",
    "            'salsa_lexical_score': sent['subscores']['lexical'],\n",
    "            'salsa_syntax_score': sent['subscores']['syntax'],\n",
    "            'salsa_conceptual_score': sent['subscores']['content'],\n",
    "\n",
    "            'salsa_quality_score': sent['subscores']['quality'],\n",
    "            'salsa_error_score': sent['subscores']['error'],\n",
    "        }\n",
    "\n",
    "        if sent['simpeval_scores'] is not None:\n",
    "            entry.update({\n",
    "                'simpeval_score_1': sent['simpeval_scores'][0],\n",
    "                'simpeval_score_2': sent['simpeval_scores'][1],\n",
    "                'simpeval_score_3': sent['simpeval_scores'][2],\n",
    "            })\n",
    "\n",
    "        # Generate word-level QE\n",
    "        for family_constraint in [None] + list(Family):\n",
    "            for sentence_type in ['original', 'simplified']:\n",
    "                tags = get_annotations_per_token([sent], sentence_type, remove_none=False, tagging=True)\n",
    "                tags_by_type = get_tag_values(tags, family_constraint)\n",
    "\n",
    "                for tag_type, tag_value in tags_by_type.items():\n",
    "                    tag_value = write_tagged_sentence(sent[sentence_type], tags, tag_value)\n",
    "                    \n",
    "                    tag_value = tag_value.replace('<ok>', '')\\\n",
    "                        .replace('</ok>', '').replace('<noedit>', '')\\\n",
    "                        .replace('</noedit>', '')\n",
    "                \n",
    "                    fam_name = f'_{Family.CONTENT.value.lower()}' if family_constraint is not None else ''\n",
    "                    entry.update({\n",
    "                        f'{tag_type}_{sentence_type}{fam_name}': tag_value\n",
    "                    })\n",
    "        \n",
    "        # Generate edit type tagging\n",
    "        for sentence_type in ['original', 'simplified']:\n",
    "            tags = get_annotations_per_token([sent], sentence_type, collapse_composite=True, remove_reorder=True, remove_none=False)\n",
    "            tags_by_type = get_edit_values(tags)\n",
    "\n",
    "            for tag_type, tag_value in tags_by_type.items():\n",
    "                tag_value = write_tagged_sentence(sent[sentence_type], tags, tag_value)\n",
    "\n",
    "                tag_value = tag_value.replace('<ok>', '').replace('</ok>', '')\n",
    "            \n",
    "                entry.update({\n",
    "                    f'{tag_type}_{sentence_type}': tag_value\n",
    "                })\n",
    "\n",
    "        # Generate traditional alignment setup\n",
    "        entry.update({\n",
    "            'alignment': get_word_alignment_string(sent),\n",
    "            'alignment-no-phrases': get_word_alignment_string(sent, collapse_phrase_alignment=True),\n",
    "            'alignment-error-labels-input': ' '.join(get_tag_values(get_annotations_per_token([sent], 'original', \\\n",
    "                remove_none=False, tagging=True))['word_qe_error_types']),\n",
    "            'alignment-error-labels-output': ' '.join(get_tag_values(get_annotations_per_token([sent], 'simplified', \\\n",
    "                remove_none=False, tagging=True))['word_qe_error_types']),\n",
    "        })\n",
    "\n",
    "        out_file += [entry]\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textit{13057} & \\textit{628} & \\textit{449} & \\textit{1901}\n"
     ]
    }
   ],
   "source": [
    "# Get number of edit types\n",
    "edits = [i for j in [s['processed_annotations'] for s in data] for i in j]\n",
    "num_error = sum([e['error_type'] is not None for e in edits])\n",
    "num_complex = sum([e['error_type'] == Error.COMPLEX_WORDING for e in edits])\n",
    "num_bad_del = sum([e['error_type'] == Error.BAD_DELETION for e in edits])\n",
    "num_quality = len(edits) - num_error\n",
    "print(\"\\\\textit{\" + str(num_quality) + \"} & \\\\textit{\" + str(num_bad_del) + \"} & \\\\textit{\" + str(num_complex) + \"} & \\\\textit{\" + str(num_error) + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textit{13057} & \\textit{628} & \\textit{449} & \\textit{1901} & -- & \\\\\n",
      "\\textit{55K} & \\textit{4.3K} & \\textit{1.8K} & \\textit{12K} & \\textit{82K} & \\\\\n"
     ]
    }
   ],
   "source": [
    "# Get number of tokens\n",
    "edits = [i for j in [s['processed_annotations'] for s in data] for i in j]\n",
    "num_error = [e['token_size'] for e in edits if e['error_type'] is not None]\n",
    "num_complex = [e['token_size'] for e in edits if e['error_type'] == Error.COMPLEX_WORDING]\n",
    "num_bad_del = [e['token_size'] for e in edits if e['error_type'] == Error.BAD_DELETION]\n",
    "num_quality = [e['token_size'] for e in edits if e['error_type'] is None] # e['type'] == Quality.QUALITY\n",
    "num_same_tok = sum([len(s['original'].split(' ') + s['simplified'].split(' ')) for s in data]) - sum([e['token_size'] for e in edits])\n",
    "\n",
    "print(\"\\\\textit{\" + str(len(num_quality)) + \"} & \\\\textit{\" + str(len(num_bad_del)) + \"} & \\\\textit{\" + str(len(num_complex)) + \"} & \\\\textit{\" + str(len(num_error)) + \"} & -- & \\\\\\\\\")\n",
    "print(\"\\\\textit{\" + str(int(sum(num_quality)/1000)) + \"K} & \\\\textit{\" + str(round(sum(num_bad_del)/1000, 1)) + \"K} & \\\\textit{\" + str(round(sum(num_complex)/1000, 1)) + \"K} & \\\\textit{\" + str(round(sum(num_error)/1000)) + \"K} & \\\\textit{\" + str(round(num_same_tok/1000)) + \"K} & \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = package_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('../data/inspection_rating_annotated', preprocess=True, adjudicated=True)\n",
    "# TODO: Add test data automatic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = package_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a split on the main data. We don't need to do this as we collected a separate test set\n",
    "# src_sents = list(set(s['src'] for s in out_file))\n",
    "# split = int(len(src_sents) * 0.7)\n",
    "# src_sents_train, src_sents_val = src_sents[:split], src_sents[split:]\n",
    "\n",
    "# write_csv('salsa/lens-salsa-training/train.csv', [s for s in out_file if s['src'] in src_sents_train])\n",
    "# write_csv('salsa/lens-salsa-training/valid.csv', [s for s in out_file if s['src'] in src_sents_val])\n",
    "\n",
    "# # Write with & without collapsed alignment\n",
    "# write_tsv_align('salsa/lens-salsa-training/train-align.tsv', [s for s in out_file if s['src'] in src_sents_train])\n",
    "# write_tsv_align('salsa/lens-salsa-training/valid-align.tsv', [s for s in out_file if s['src'] in src_sents_val])\n",
    "\n",
    "# write_tsv_align('salsa/lens-salsa-training/train-align-collapsed.tsv', [s for s in out_file if s['src'] in src_sents_train], collapse_phrase_alignment=True)\n",
    "# write_tsv_align('salsa/lens-salsa-training/valid-align-collapsed.tsv', [s for s in out_file if s['src'] in src_sents_val], collapse_phrase_alignment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('salsa/lens-salsa-training/train.csv', train_data)\n",
    "write_csv('salsa/lens-salsa-training/valid.csv', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write with & without collapsed alignment\n",
    "write_tsv_align('salsa/lens-salsa-training/train-align.tsv', train_data)\n",
    "write_tsv_align('salsa/lens-salsa-training/valid-align.tsv', test_data)\n",
    "\n",
    "write_tsv_align('salsa/lens-salsa-training/train-align-collapsed.tsv', train_data, collapse_phrase_alignment=True)\n",
    "write_tsv_align('salsa/lens-salsa-training/valid-align-collapsed.tsv', test_data, collapse_phrase_alignment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0-0 0-1 0-2 1-0 1-1 1-2 2-0 2-1 2-2 3-0 3-1 3-2 4-0 4-1 4-2 5-3 6-4 7-5 8-5 9-6 10-7 11-8 12-11 14-12 15-13 16-14 17-15 18-16 19-17 19-18 19-19 19-20 19-21 20-17 20-18 20-19 20-20 20-21 21-17 21-18 21-19 21-20 21-21 22-22 23-23 24-24 24-25 25-33 26-34 26-35 27-36 28-37 29-38 30-39 31-40 32-41 33-42 34-43 35-44 36-45 37-46 38-47 39-48 40-49 41-50 42-51 45-26 45-27 45-28 45-29 46-26 46-27 46-28 46-29 47-26 47-27 47-28 47-29 48-26 48-27 48-28 48-29 49-26 49-27 49-28 49-29 50-26 50-27 50-28 50-29 51-26 51-27 51-28 51-29 52-26 52-27 52-28 52-29 53-26 53-27 53-28 53-29'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing\n",
    "collapse_phrase_alignment = False\n",
    "\n",
    "orig_tags = get_annotations_per_token([sent], 'original', collapse_composite=True, remove_reorder=True, \\\n",
    "    remove_none=False, get_alignment=True)\n",
    "simp_tags = get_annotations_per_token([sent], 'simplified', collapse_composite=True, remove_reorder=True, \\\n",
    "    remove_none=False, get_alignment=True)\n",
    "\n",
    "word_alignment = get_word_alignment(orig_tags, simp_tags, sent)\n",
    "alignment = align_edits(word_alignment, orig_tags, simp_tags, sent, collapse_phrase_alignment)\n",
    "\n",
    "orig_tags = get_annotations_per_token([sent], 'original', collapse_composite=True, remove_reorder=True, \\\n",
    "    remove_none=False)\n",
    "simp_tags = get_annotations_per_token([sent], 'simplified', collapse_composite=True, remove_reorder=True, \\\n",
    "    remove_none=False)\n",
    "\n",
    "orig_ids = {k: i for i, k in enumerate(orig_tags.keys()) if orig_tags[k] is not set()}\n",
    "simp_ids = {k: i for i, k in enumerate(simp_tags.keys()) if simp_tags[k] is not set()}\n",
    "\n",
    "' '.join([f\"{orig_ids[x[0]]}-{simp_ids[x[1]]}\" for x in alignment])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
