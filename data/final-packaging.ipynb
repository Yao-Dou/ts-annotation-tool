{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Injestion\n",
    "Create `simpeval_22_ajudicated.json` and `simpeval_ext_ajudicated.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading files: ['../data/inspection_rating_annotated/batch_1_ayush.json', '../data/inspection_rating_annotated/batch_1_rachel.json', '../data/inspection_rating_annotated/batch_1_vinayak.json', '../data/inspection_rating_annotated/batch_1_vishnesh.json', '../data/inspection_rating_annotated/batch_2_ayush.json', '../data/inspection_rating_annotated/batch_2_rachel.json', '../data/inspection_rating_annotated/batch_2_vinayak.json', '../data/inspection_rating_annotated/batch_2_vishnesh.json', '../data/inspection_rating_annotated/batch_3_ayush.json', '../data/inspection_rating_annotated/batch_3_rachel.json', '../data/inspection_rating_annotated/batch_3_vishnesh.json', '../data/inspection_rating_annotated/batch_4_ayush.json']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Found users: {'vishnesh', 'vinayak', 'ayush', 'rachel'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180: simpeval-22/Muss\n",
      "169: simpeval-22/GPT-3-few-shot\n",
      "180: simpeval-22/Human-2-written\n",
      "170: simpeval-22/T5-11B\n",
      "180: simpeval-22/Human-1-written\n",
      "170: simpeval-22/GPT-3-zero-shot\n",
      "169: simpeval-22/T5-3B\n",
      "\n",
      "53: simpeval-ext/Human-1-written\n",
      "63: simpeval-ext/GPT-3-zero-shot\n",
      "60: simpeval-ext/Human-2-written\n",
      "63: simpeval-ext/Muss\n",
      "60: simpeval-ext/T5-3B\n",
      "57: simpeval-ext/GPT-3-few-shot\n",
      "59: simpeval-ext/T5-11B\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../analysis')\n",
    "from utils.all import *\n",
    "log.basicConfig(level=log.INFO)\n",
    "data = load_data('../data/inspection_rating_annotated', preprocess=False, adjudicated=True)\n",
    "\n",
    "simpeval_22, simpeval_ext = [], []\n",
    "for sent in data:\n",
    "    if 'simpeval-22' in sent['system']:\n",
    "        simpeval_22 += [sent]\n",
    "    elif 'simpeval-ext' in sent['system']:\n",
    "        simpeval_ext += [sent]\n",
    "\n",
    "# Sanity check: Count the # annotations per system\n",
    "def number_annotations_per_system(data):\n",
    "    systems = set([s['system'] for s in data])\n",
    "    for system in systems:\n",
    "        print(f\"{len([s for s in data if s['system'] == system])}: {system}\")\n",
    "number_annotations_per_system(simpeval_22)\n",
    "print('')\n",
    "number_annotations_per_system(simpeval_ext)\n",
    "\n",
    "with open(f\"salsa/simpeval_22_ajudicated.json\", \"w\") as f:\n",
    "   json.dump(simpeval_22, f, indent=4)\n",
    "\n",
    "with open(f\"salsa/simpeval_ext_ajudicated.json\", \"w\") as f:\n",
    "   json.dump(simpeval_ext, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LENS-SALSA Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('../data/inspection_rating_annotated', preprocess=True, adjudicated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENS uses a CSV input format:\n",
    "\n",
    "# original_id\n",
    "# original\n",
    "# generation\n",
    "# system\n",
    "# sentence_type\n",
    "# rating_1\n",
    "# rating_2\n",
    "# rating_3\n",
    "# rating_1_zscore\n",
    "# rating_2_zscore\n",
    "# rating_3_zscore\n",
    "\n",
    "# For our first output, we need these columns:\n",
    "\n",
    "# sentence_id\n",
    "# original\n",
    "# generation\n",
    "# system\n",
    "# simpeval_score\n",
    "# salsa_score\n",
    "# salsa_lexical_score\n",
    "# salsa_syntax_score\n",
    "# salsa_conceptual_score\n",
    "# word_qe - Edits are surrounded by <bad></bad>, <good></good>\n",
    "# word_ratings - Edits are surrounded by <3></3>, <2></2>, etc.\n",
    "# edit_qe - Edits are surrounded by <edit></edit>\n",
    "\n",
    "# I want to generate the above 3 multiple times for each edit type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_values(tags, family_constraint=None):\n",
    "    # Recover word QE\n",
    "    word_qe, word_ratings, edit_qe = [], [], []\n",
    "    for tag in tags.keys():\n",
    "        ratings = [i for j in tags[tag].values() for i in j]\n",
    "        if family_constraint:\n",
    "            ratings = [ann for ann in ratings if ann['family'] == family_constraint]\n",
    "\n",
    "        # whether each word is good/bad/ok, bad > good > ok\n",
    "        word_quality = 'ok'\n",
    "        if any([edit['word_qe'] == 'bad' for edit in ratings]):\n",
    "            word_quality = 'bad'\n",
    "        elif any([edit['word_qe'] == 'good' for edit in ratings]):\n",
    "            word_quality = 'good'\n",
    "        word_qe += [word_quality]\n",
    "\n",
    "        # word rating, greater magnitude is king\n",
    "        word_rating = 0\n",
    "        if len(ratings) != 0:\n",
    "            word_rating = max([edit['word_rating'] for edit in ratings if edit['word_rating'] is not None] + [0], key=abs)\n",
    "        word_ratings += [word_rating]\n",
    "\n",
    "        # whether edit exists, edit > no edit\n",
    "        edit_qe += ['edit' if any([edit['edit_qe'] for edit in ratings]) else 'noedit']\n",
    "    return word_qe, word_ratings, edit_qe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<1>The architecture of Winchester College is</1> <0>a</0> <1>diverse set</1> <0>of architectural styles,</0> <1>reflecting</1> <0>the multiple periods of building from</0> <1>the college's foundation</1> <0>in 1382,</0> <1>through additions in the medieval and Early Modern periods,</1> <0>to a major expansion of accommodation in the Victorian era</0> <1>and then</1> <2>further extensions at the turn of the 20th century</2> <1>and more recently.</1>\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover the sentence iteratively, as in only switch tags when the\n",
    "# array value has changed\n",
    "def write_tagged_sentence(sent, tags, tag_values):\n",
    "    prev_value = None\n",
    "    orig = sent\n",
    "    out = \"\"\n",
    "    for i, span in enumerate(list(tags.keys())):\n",
    "        curr_value = tag_values[i]\n",
    "        if prev_value == None:\n",
    "            out += f\"<{curr_value}>\"\n",
    "        elif prev_value != curr_value:\n",
    "            out += f\"</{prev_value}> <{curr_value}>\"\n",
    "        else:\n",
    "            out += \" \"\n",
    "\n",
    "        out += f'{orig[span[0]:span[1]]}'\n",
    "\n",
    "        prev_value = curr_value\n",
    "    out += f'</{prev_value}>'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = []\n",
    "for sent in data:\n",
    "    entry = {\n",
    "        'sentence_id': sent['sentence_id'],\n",
    "        'original': sent['original'],\n",
    "        'generation': sent['simplified'],\n",
    "        'system': sent['system'],\n",
    "        'salsa_score': sent['score'],\n",
    "        'simpeval_score_1': None,\n",
    "        'simpeval_score_2': None,\n",
    "        'simpeval_score_3': None,\n",
    "\n",
    "        # Subscores\n",
    "        'salsa_lexical_quality_score': sent['subscores']['quality_lexical'],\n",
    "        'salsa_syntax_quality_score': sent['subscores']['quality_syntax'],\n",
    "        'salsa_conceptual_quality_score': sent['subscores']['quality_content'],\n",
    "\n",
    "        'salsa_lexical_error_score': sent['subscores']['error_lexical'],\n",
    "        'salsa_syntax_error_score': sent['subscores']['error_syntax'],\n",
    "        'salsa_conceptual_error_score': sent['subscores']['error_content'],\n",
    "\n",
    "        'salsa_lexical_score': sent['subscores']['lexical'],\n",
    "        'salsa_syntax_score': sent['subscores']['syntax'],\n",
    "        'salsa_conceptual_score': sent['subscores']['content'],\n",
    "\n",
    "        'salsa_quality_score': sent['subscores']['quality'],\n",
    "        'salsa_error_score': sent['subscores']['error'],\n",
    "    }\n",
    "\n",
    "    if sent['simpeval_scores'] is not None:\n",
    "        entry.update({\n",
    "            'simpeval_score_1': sent['simpeval_scores'][0],\n",
    "            'simpeval_score_2': sent['simpeval_scores'][1],\n",
    "            'simpeval_score_3': sent['simpeval_scores'][2],\n",
    "        })\n",
    "\n",
    "    # Generate word-level QE\n",
    "    for family_constraint in [None] + list(Family):\n",
    "        for sentence_type in ['original', 'simplified']:\n",
    "            tags = get_annotations_per_token([sent], sentence_type, remove_none=False, tagging=True)\n",
    "            word_qe, word_ratings, edit_qe = get_tag_values(tags, family_constraint)\n",
    "\n",
    "            word_qe = write_tagged_sentence(sent[sentence_type], tags, word_qe)\n",
    "            word_ratings = write_tagged_sentence(sent[sentence_type], tags, word_ratings)\n",
    "            edit_qe = write_tagged_sentence(sent[sentence_type], tags, edit_qe)\n",
    "            \n",
    "            fam_name = f'_{Family.CONTENT.value.lower()}' if family_constraint is not None else ''\n",
    "            entry.update({\n",
    "                f'word_qe_{sentence_type}{fam_name}': word_qe,\n",
    "                f'word_ratings_{sentence_type}{fam_name}': word_ratings,\n",
    "                f'edit_qe_{sentence_type}{fam_name}': edit_qe,\n",
    "            })\n",
    "\n",
    "    out_file += [entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "headers = list(out_file[0].keys())\n",
    "with open('salsa/lens_salsa_training.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for row in out_file:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
