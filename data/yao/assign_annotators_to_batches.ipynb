{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('humans-output-new-wiki-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotater_list = list(set(df['Human 1'].unique().tolist() + df['Human 2'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a id list for each row of df\n",
    "df['id'] = df.index\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with annotater as key and empty list as value\n",
    "annotater_dict = {}\n",
    "for annotater in annotater_list:\n",
    "    annotater_dict[annotater] = []\n",
    "\n",
    "# create a dictionary with id as key and empty list as value\n",
    "id_dict = {}\n",
    "for id in df['id'].tolist():\n",
    "    id_dict[id] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going through each row of df\n",
    "for index, row in df.iterrows():\n",
    "    annotater_one = row['Human 1']\n",
    "    annotater_two = row['Human 2']\n",
    "    remaining_annotaters = list(set(annotater_list) - set([annotater_one, annotater_two]))\n",
    "    # random sampling 3 annotaters from remaining annotaters\n",
    "    for annotater in remaining_annotaters:\n",
    "        if len(annotater_dict[annotater]) == 15:\n",
    "            remaining_annotaters.remove(annotater)\n",
    "            break\n",
    "    annotaters = random.sample(remaining_annotaters, 3)\n",
    "    for annotater in annotaters:\n",
    "        annotater_dict[annotater].append(row['id'])\n",
    "        id_dict[row['id']].append(annotater)\n",
    "    \n",
    "    id_dict[row['id']] = annotaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kelly 15\n",
      "vinayak 15\n",
      "vishnesh 12\n",
      "anton 15\n",
      "rachel 16\n",
      "ayush 17\n"
     ]
    }
   ],
   "source": [
    "# print length of each annotater's list\n",
    "for annotater in annotater_dict:\n",
    "    print(annotater, len(annotater_dict[annotater]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['anton', 'vinayak', 'ayush'],\n",
       " 1: ['rachel', 'vishnesh', 'anton'],\n",
       " 2: ['ayush', 'vinayak', 'anton'],\n",
       " 3: ['vishnesh', 'ayush', 'vinayak'],\n",
       " 4: ['vinayak', 'kelly', 'anton'],\n",
       " 5: ['rachel', 'ayush', 'kelly'],\n",
       " 6: ['kelly', 'vishnesh', 'ayush'],\n",
       " 7: ['ayush', 'rachel', 'vinayak'],\n",
       " 8: ['vinayak', 'anton', 'vishnesh'],\n",
       " 9: ['anton', 'vishnesh', 'kelly'],\n",
       " 10: ['anton', 'vinayak', 'rachel'],\n",
       " 11: ['kelly', 'vishnesh', 'vinayak'],\n",
       " 12: ['kelly', 'vinayak', 'ayush'],\n",
       " 13: ['ayush', 'vinayak', 'rachel'],\n",
       " 14: ['kelly', 'anton', 'vishnesh'],\n",
       " 15: ['ayush', 'kelly', 'anton'],\n",
       " 16: ['anton', 'vinayak', 'rachel'],\n",
       " 17: ['ayush', 'rachel', 'kelly'],\n",
       " 18: ['vinayak', 'rachel', 'ayush'],\n",
       " 19: ['vinayak', 'kelly', 'anton'],\n",
       " 20: ['kelly', 'vinayak', 'vishnesh'],\n",
       " 21: ['ayush', 'rachel', 'vinayak'],\n",
       " 22: ['anton', 'ayush', 'vishnesh'],\n",
       " 23: ['rachel', 'vishnesh', 'kelly'],\n",
       " 24: ['kelly', 'rachel', 'vishnesh'],\n",
       " 25: ['kelly', 'anton', 'rachel'],\n",
       " 26: ['ayush', 'kelly', 'rachel'],\n",
       " 27: ['ayush', 'anton', 'rachel'],\n",
       " 28: ['ayush', 'anton', 'rachel'],\n",
       " 29: ['ayush', 'vishnesh', 'rachel']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict[16] = ['vinayak', 'rachel', 'vishnesh']\n",
    "id_dict[21] = ['ayush', 'vinayak', 'rachel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat annotaer_dict based on id_dict\n",
    "for annotater in annotater_dict:\n",
    "    annotater_dict[annotater] = []\n",
    "    for id in id_dict:\n",
    "        if annotater in id_dict[id]:\n",
    "            annotater_dict[annotater].append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # save annotater_dict to json\n",
    "# with open('annotater_dict-new-wiki-1.json', 'w') as fp:\n",
    "#     json.dump(annotater_dict, fp)\n",
    "\n",
    "# # save id_dict to json\n",
    "# with open('id_dict-new-wiki-1.json', 'w') as fp:\n",
    "#     json.dump(id_dict, fp)\n",
    "import json\n",
    "\n",
    "annotater_dict = json.load(open('annotater_dict-new-wiki-1.json'))\n",
    "id_dict = json.load(open('id_dict-new-wiki-1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinayak 15\n",
      "kelly 15\n",
      "rachel 15\n",
      "vishnesh 15\n",
      "ayush 15\n",
      "anton 15\n"
     ]
    }
   ],
   "source": [
    "# print length of each annotater's list\n",
    "for annotater in annotater_dict:\n",
    "    print(annotater, len(annotater_dict[annotater]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random switch human 1 and human 2 and their writings\n",
    "for index, row in df.iterrows():\n",
    "    if random.random() > 0.5:\n",
    "        df.loc[index, 'Human 1'] = row['Human 2']\n",
    "        df.loc[index, 'Human 2'] = row['Human 1']\n",
    "        df.loc[index, 'Human 1 Writing'] = row['Human 2 Writing']\n",
    "        df.loc[index, 'Human 2 Writing'] = row['Human 1 Writing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../gpt-3/gpt3-output.json') as f:\n",
    "    gpt3_zeroshot = json.load(f)\n",
    "\n",
    "# few-shot\n",
    "with open('../gpt-3/gpt3-few-shot-output.json') as f:\n",
    "    gpt3_fewshot = json.load(f)\n",
    "\n",
    "with open(\"muss-output-new-wiki-1.json\") as f:\n",
    "    muss = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GPT-3-zero-shot'] = gpt3_zeroshot\n",
    "df['GPT-3-few-shot'] = gpt3_fewshot\n",
    "df['Muss'] = muss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yaod_1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "def remove_tokenization_artifacts(s, src):\n",
    "    stokens = s.split()\n",
    "    snew = s\n",
    "    for i, token in enumerate(stokens):\n",
    "        if i > 0 and i < len(stokens) - 1 and token in punctuation:\n",
    "            substrboth = stokens[i - 1] + token + stokens[i + 1]\n",
    "            substrleft = stokens[i - 1] + token\n",
    "            substright = token + stokens[i + 1]\n",
    "            if substrboth in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token + \" \" + stokens[i + 1], substrboth)\n",
    "            elif substrleft in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token, substrleft)\n",
    "            elif substright in src:\n",
    "                snew = snew.replace(token + \" \" + stokens[i + 1], substright)\n",
    "\n",
    "    snew = snew.replace(\"''\", '\"')\n",
    "    snew = snew.replace(\" .\", \".\")\n",
    "    snew_rest = \"\" if len(snew) == 1 else snew[1:]\n",
    "    if len(snew) > 0:\n",
    "        snew = snew[0].capitalize() + snew_rest\n",
    "    snew = snew.replace(\"-lrb-\", \"(\").replace(\"-rrb-\", \")\")\n",
    "    snew = snew.replace(\"-LRB-\", \"(\").replace(\"-RRB-\", \")\")\n",
    "    return snew\n",
    "\n",
    "def reformat_output(output, original):\n",
    "    output = remove_tokenization_artifacts(output, original)\n",
    "    output = \" || \".join(sent_tokenize(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat output with reformat_output function\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'Human 1 Writing'] = reformat_output(row['Human 1 Writing'], row['Original Sentence'])\n",
    "    df.loc[index, 'Human 2 Writing'] = reformat_output(row['Human 2 Writing'], row['Original Sentence'])\n",
    "    df.loc[index, 'GPT-3-zero-shot'] = reformat_output(row['GPT-3-zero-shot'], row['Original Sentence'])\n",
    "    df.loc[index, 'GPT-3-few-shot'] = reformat_output(row['GPT-3-few-shot'], row['Original Sentence'])\n",
    "    df.loc[index, 'Muss'] = reformat_output(row['Muss'], row['Original Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all-outputs-new-wiki-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'vinayak': [0, 1, 3, 7, 8, 10, 11, 13, 16, 18, 19, 20, 21, 22, 23],\n",
    "#  'kelly': [0, 3, 4, 5, 9, 12, 13, 14, 15, 17, 23, 24, 25, 26, 28],\n",
    "#  'rachel': [1, 2, 10, 11, 14, 16, 19, 21, 23, 24, 25, 26, 27, 28, 29],\n",
    "#  'vishnesh': [1, 3, 4, 5, 6, 7, 9, 11, 14, 15, 16, 17, 18, 20, 29],\n",
    "#  'ayush': [2, 5, 6, 7, 8, 9, 12, 13, 17, 18, 21, 22, 26, 27, 28],\n",
    "#  'anton': [0, 2, 4, 6, 8, 10, 12, 15, 19, 20, 22, 24, 25, 27, 29]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vinayak': [0, 1, 3, 7, 8, 10, 11, 13, 16, 18, 19, 20, 21, 22, 23],\n",
       " 'kelly': [0, 3, 4, 5, 9, 12, 13, 14, 15, 17, 23, 24, 25, 26, 28],\n",
       " 'rachel': [1, 2, 10, 11, 14, 16, 19, 21, 23, 24, 25, 26, 27, 28, 29],\n",
       " 'vishnesh': [1, 3, 4, 5, 6, 7, 9, 11, 14, 15, 16, 17, 18, 20, 29],\n",
       " 'ayush': [2, 5, 6, 7, 8, 9, 12, 13, 17, 18, 21, 22, 26, 27, 28],\n",
       " 'anton': [0, 2, 4, 6, 8, 10, 12, 15, 19, 20, 22, 24, 25, 27, 29]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotater_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "system_list = [\"Human 1 Writing\", \"Human 2 Writing\", \"GPT-3-zero-shot\", \"GPT-3-few-shot\", \"Muss\"]\n",
    "for annotater in annotater_dict:\n",
    "    annotater_batch = []\n",
    "    start_id = 0\n",
    "    for id in annotater_dict[annotater]:\n",
    "        # get the id th row of df\n",
    "        row = df.iloc[id]\n",
    "        random.seed(2)\n",
    "        # random shuffle the system list\n",
    "        random.shuffle(system_list)\n",
    "        for system in system_list:\n",
    "            current_dict = {}\n",
    "            current_dict[\"id\"] = start_id\n",
    "            current_dict[\"original\"] = row[\"Original Sentence\"].strip()\n",
    "            current_dict[\"original_spans\"] = []\n",
    "\n",
    "            simplified = row[system].strip()\n",
    "            simplified = re.sub(r\" 's\", \"'s\", simplified)\n",
    "            current_dict[\"simplified\"] = simplified\n",
    "            current_dict[\"simplified_spans\"] = []\n",
    "\n",
    "            if \"||\" in simplified:\n",
    "                #  find index of all || in simplified\n",
    "                indices = [m.start() for m in re.finditer('\\|\\|', simplified)]\n",
    "                for i, indice in enumerate(indices):\n",
    "                    current_dict[\"simplified_spans\"].append([2, indice, indice+2, i])\n",
    "            \n",
    "            current_dict[\"system\"] = \"new-wiki-1/\" + system\n",
    "            annotater_batch.append(current_dict)\n",
    "            start_id += 1\n",
    "\n",
    "    # split annotater_batch into 2 batches first 40 and last 35\n",
    "    annotater_batch_1 = annotater_batch[:40]\n",
    "    annotater_batch_2 = annotater_batch[40:]\n",
    "\n",
    "    with open(\"../batches/new-wiki-1/part1/\" + annotater + \".json\", \"w\") as f:\n",
    "        json.dump(annotater_batch_1, f, indent=4)\n",
    "\n",
    "    # reindex annotater_batch_2's id from 0\n",
    "    for i, item in enumerate(annotater_batch_2):\n",
    "        item[\"id\"] = i\n",
    "\n",
    "    with open(\"../batches/new-wiki-1/part2/\" + annotater + \".json\", \"w\") as f:\n",
    "        json.dump(annotater_batch_2, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('paraphrase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d4b053945bb951b16f24566ff3322f1cf2f2e71937c6e2fa134fa8352168a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
