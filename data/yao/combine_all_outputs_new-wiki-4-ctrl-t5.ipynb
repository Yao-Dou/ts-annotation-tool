{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "which_wiki =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# original_sentences\n",
    "with open(f'new_wiki_original_sentences_{which_wiki}.txt') as f:\n",
    "    original_sentences = f.readlines()\n",
    "    for i in range(len(original_sentences)):\n",
    "        original_sentences[i] = original_sentences[i].strip()\n",
    "\n",
    "# ctrl-t5-3b\n",
    "with open(f'ctrl-t5-3B-new-wiki-{which_wiki}-output.txt') as f:\n",
    "    t5_3b = f.readlines()\n",
    "    for i in range(len(t5_3b)):\n",
    "        t5_3b[i] = t5_3b[i].strip()\n",
    "\n",
    "# ctrl-t5-11b\n",
    "with open(f'ctrl-t5-11B-new-wiki-{which_wiki}-output.txt') as f:\n",
    "    t5_11b = f.readlines()\n",
    "    for i in range(len(t5_11b)):\n",
    "        t5_11b[i] = t5_11b[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe with all outputs\n",
    "df = pd.DataFrame()\n",
    "df['Original Sentence'] = original_sentences\n",
    "df['Ctrl-T5-3b'] = t5_3b\n",
    "df['Ctrl-T5-11b'] = t5_11b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'all-outputs-new-wiki-{which_wiki}-ctrl-t5-before-splitting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yaod_1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "def remove_tokenization_artifacts(s, src):\n",
    "    stokens = s.split()\n",
    "    snew = s\n",
    "    for i, token in enumerate(stokens):\n",
    "        if i > 0 and i < len(stokens) - 1 and token in punctuation:\n",
    "            substrboth = stokens[i - 1] + token + stokens[i + 1]\n",
    "            substrleft = stokens[i - 1] + token\n",
    "            substright = token + stokens[i + 1]\n",
    "            if substrboth in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token + \" \" + stokens[i + 1], substrboth)\n",
    "            elif substrleft in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token, substrleft)\n",
    "            elif substright in src:\n",
    "                snew = snew.replace(token + \" \" + stokens[i + 1], substright)\n",
    "\n",
    "    snew = snew.replace(\"''\", '\"')\n",
    "    snew = snew.replace(\" .\", \".\")\n",
    "    snew_rest = \"\" if len(snew) == 1 else snew[1:]\n",
    "    if len(snew) > 0:\n",
    "        snew = snew[0].capitalize() + snew_rest\n",
    "    snew = snew.replace(\"-lrb-\", \"(\").replace(\"-rrb-\", \")\")\n",
    "    snew = snew.replace(\"-LRB-\", \"(\").replace(\"-RRB-\", \")\")\n",
    "    return snew\n",
    "\n",
    "def reformat_output(output, original):\n",
    "    output = remove_tokenization_artifacts(output, original)\n",
    "    output = \" || \".join(sent_tokenize(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat output with reformat_output function\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'Ctrl-T5-3b'] = reformat_output(row['Ctrl-T5-3b'], row['Original Sentence'])\n",
    "    df.loc[index, 'Ctrl-T5-11b'] = reformat_output(row['Ctrl-T5-11b'], row['Original Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'all-outputs-new-wiki-{which_wiki}-ctrl-t5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('paraphrase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d4b053945bb951b16f24566ff3322f1cf2f2e71937c6e2fa134fa8352168a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
