{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Roberta and T5\n",
    "\n",
    "It is in the following format:\n",
    "\n",
    "*Input*: [CLS] original sentence [SEP] simplified <special> ... </special> sentence [SEP]\n",
    "\n",
    "*Label*: quality, trivial, error\n",
    "\n",
    "Only need sentence1, sentence2 and label columns, hugginface will automatically add [CLS] and [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "split_name = \"test\"\n",
    "\n",
    "with open(f\"../data/edit_classification/inspection_data/{split_name}_1234.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "keys = list(data.keys())\n",
    "# keys is a string which delimiter is %%, so split into a tuple, and replace keys\n",
    "keys = [tuple(key.split('%%')) for key in keys]\n",
    "data = dict(zip(keys, data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_2_special_token_start = {\"deletion\": \"<DEL>\", \"insertion\": \"<INS>\", \"substitution\": \"<SUB>\", \"reorder\": \"<REO>\", \n",
    "                                \"structure\": \"<STR>\", \"split\": \"<SPLIT>\"}\n",
    "edit_2_special_token_end = {\"deletion\": \"</DEL>\", \"insertion\": \"</INS>\", \"substitution\": \"</SUB>\", \"reorder\": \"</REO>\",\n",
    "                                \"structure\": \"</STR>\", \"split\": \"</SPLIT>\"}\n",
    "\n",
    "original_list = []                       \n",
    "sentence1_list = []\n",
    "sentence2_list = []\n",
    "label_list = []\n",
    "\n",
    "for key, annotation in data.items():\n",
    "    system, original = key\n",
    "    simplified = annotation['simplified']\n",
    "    for i, edit in enumerate(annotation[\"edits\"]):\n",
    "        edit_type = edit[\"type\"]\n",
    "        original_spans = edit[\"original_span\"]\n",
    "        simplified_spans = edit[\"simplified_span\"]\n",
    "        label = edit[\"label\"]\n",
    "        # each span is a tuple (start, end), sort by start, then end\n",
    "        if original_spans is None:\n",
    "            new_original = original\n",
    "        else:\n",
    "            original_spans.sort(key=lambda x: (x[0], x[1]))\n",
    "            new_original = original[:original_spans[0][0]]\n",
    "            for j, span in enumerate(original_spans):\n",
    "                new_original += edit_2_special_token_start[edit_type]\n",
    "                new_original += original[span[0]:span[1]]\n",
    "                new_original += edit_2_special_token_end[edit_type]\n",
    "                if j < len(original_spans) - 1:\n",
    "                    new_original += original[original_spans[j][1]:original_spans[j+1][0]]\n",
    "            new_original += original[original_spans[-1][1]:]\n",
    "        \n",
    "        if simplified_spans is None:\n",
    "            new_simplified = simplified\n",
    "        else:\n",
    "            simplified_spans.sort(key=lambda x: (x[0], x[1]))\n",
    "            new_simplified = simplified[:simplified_spans[0][0]]\n",
    "            for j, span in enumerate(simplified_spans):\n",
    "                if simplified[span[0]:span[1]] == \"||\":\n",
    "                    new_simplified += \"<SPLIT_SIGN>\"\n",
    "                else:\n",
    "                    new_simplified += edit_2_special_token_start[edit_type]\n",
    "                    new_simplified += simplified[span[0]:span[1]]\n",
    "                    new_simplified += edit_2_special_token_end[edit_type]\n",
    "                if j < len(simplified_spans) - 1:\n",
    "                    new_simplified += simplified[simplified_spans[j][1]:simplified_spans[j+1][0]]\n",
    "            new_simplified += simplified[simplified_spans[-1][1]:]\n",
    "        \n",
    "        # replace \"|| \" in simplified with \"\"\n",
    "        new_simplified = new_simplified.replace(\"|| \", \"\")\n",
    "        new_simplified = new_simplified.replace(\"<SPLIT_SIGN> \", \"<SPLIT_SIGN>\")\n",
    "        \n",
    "        original_list.append(original)\n",
    "        sentence1_list.append(new_original)\n",
    "        sentence2_list.append(new_simplified)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'error': 66, 'quality': 394, 'trivial': 73})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of each label in label_list\n",
    "from collections import Counter\n",
    "Counter(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame({\"original\": original_list, \"sentence1\": sentence1_list, \"sentence2\": sentence2_list, \"label\": label_list})\n",
    "\n",
    "# save to csv\n",
    "df.to_csv(f\"../data/edit_classification/inspection_data/classification_data/{split_name}_1234.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('paraphrase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d4b053945bb951b16f24566ff3322f1cf2f2e71937c6e2fa134fa8352168a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
